{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import R2Score, BinaryAccuracy, BinaryAUROC\n",
    "\n",
    "from molsetrep.utils.torch_trainer import TorchTrainer\n",
    "from molsetrep.utils.datasets import molnet_loader\n",
    "from molsetrep.utils.converters import molnet_to_pyg\n",
    "from molsetrep.utils.root_mean_squared_error import RootMeanSquaredError\n",
    "from molsetrep.utils.imbalanced_sampler import ImbalancedSampler\n",
    "from molsetrep.models import SetRepClassifier, SetRepRegressor\n",
    "from molsetrep.encoders import SECMQNFPEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = molnet_loader(\"bace_classification\")\n",
    "enc = SECMQNFPEncoder()\n",
    "\n",
    "train_dataset = enc.encode(train.ids, [y[0] for y in train.y], label_dtype=torch.long)\n",
    "valid_dataset = enc.encode(valid.ids, [y[0] for y in valid.y], label_dtype=torch.long)\n",
    "test_dataset = enc.encode(test.ids, [y[0] for y in test.y], label_dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=ImbalancedSampler(train_dataset))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Epoch 1: Train loss: 0.679 (BinaryAccuracy: 0.57, BinaryAUROC: 0.563)  Valid loss: 0.659 (BinaryAccuracy: 0.563, BinaryAUROC: 0.523)\n",
      "|  Epoch 2: Train loss: 0.681 (BinaryAccuracy: 0.576, BinaryAUROC: 0.572)  Valid loss: 0.666 (BinaryAccuracy: 0.563, BinaryAUROC: 0.523)\n",
      "|  Epoch 3: Train loss: 0.672 (BinaryAccuracy: 0.609, BinaryAUROC: 0.603)  Valid loss: 0.658 (BinaryAccuracy: 0.563, BinaryAUROC: 0.521)\n",
      "|  Epoch 4: Train loss: 0.668 (BinaryAccuracy: 0.616, BinaryAUROC: 0.617)  Valid loss: 0.648 (BinaryAccuracy: 0.556, BinaryAUROC: 0.514)\n",
      "*  Epoch 5: Train loss: 0.655 (BinaryAccuracy: 0.668, BinaryAUROC: 0.667)  Valid loss: 0.637 (BinaryAccuracy: 0.589, BinaryAUROC: 0.546)\n",
      "|  Epoch 6: Train loss: 0.65 (BinaryAccuracy: 0.675, BinaryAUROC: 0.678)  Valid loss: 0.63 (BinaryAccuracy: 0.589, BinaryAUROC: 0.546)\n",
      "|  Epoch 7: Train loss: 0.641 (BinaryAccuracy: 0.702, BinaryAUROC: 0.702)  Valid loss: 0.63 (BinaryAccuracy: 0.563, BinaryAUROC: 0.529)\n",
      "*  Epoch 8: Train loss: 0.639 (BinaryAccuracy: 0.662, BinaryAUROC: 0.661)  Valid loss: 0.633 (BinaryAccuracy: 0.583, BinaryAUROC: 0.556)\n",
      "|  Epoch 9: Train loss: 0.638 (BinaryAccuracy: 0.666, BinaryAUROC: 0.666)  Valid loss: 0.633 (BinaryAccuracy: 0.583, BinaryAUROC: 0.556)\n",
      "*  Epoch 10: Train loss: 0.644 (BinaryAccuracy: 0.666, BinaryAUROC: 0.666)  Valid loss: 0.634 (BinaryAccuracy: 0.589, BinaryAUROC: 0.566)\n",
      "*  Epoch 11: Train loss: 0.645 (BinaryAccuracy: 0.647, BinaryAUROC: 0.648)  Valid loss: 0.634 (BinaryAccuracy: 0.596, BinaryAUROC: 0.573)\n",
      "*  Epoch 12: Train loss: 0.634 (BinaryAccuracy: 0.668, BinaryAUROC: 0.667)  Valid loss: 0.634 (BinaryAccuracy: 0.609, BinaryAUROC: 0.588)\n",
      "|  Epoch 13: Train loss: 0.633 (BinaryAccuracy: 0.681, BinaryAUROC: 0.681)  Valid loss: 0.634 (BinaryAccuracy: 0.596, BinaryAUROC: 0.575)\n",
      "*  Epoch 14: Train loss: 0.627 (BinaryAccuracy: 0.692, BinaryAUROC: 0.692)  Valid loss: 0.636 (BinaryAccuracy: 0.616, BinaryAUROC: 0.596)\n",
      "*  Epoch 15: Train loss: 0.619 (BinaryAccuracy: 0.694, BinaryAUROC: 0.693)  Valid loss: 0.633 (BinaryAccuracy: 0.623, BinaryAUROC: 0.603)\n",
      "|  Epoch 16: Train loss: 0.626 (BinaryAccuracy: 0.682, BinaryAUROC: 0.682)  Valid loss: 0.635 (BinaryAccuracy: 0.616, BinaryAUROC: 0.6)\n",
      "|  Epoch 17: Train loss: 0.636 (BinaryAccuracy: 0.645, BinaryAUROC: 0.646)  Valid loss: 0.636 (BinaryAccuracy: 0.616, BinaryAUROC: 0.6)\n",
      "*  Epoch 18: Train loss: 0.633 (BinaryAccuracy: 0.669, BinaryAUROC: 0.67)  Valid loss: 0.635 (BinaryAccuracy: 0.629, BinaryAUROC: 0.611)\n",
      "|  Epoch 19: Train loss: 0.623 (BinaryAccuracy: 0.696, BinaryAUROC: 0.694)  Valid loss: 0.634 (BinaryAccuracy: 0.629, BinaryAUROC: 0.611)\n",
      "|  Epoch 20: Train loss: 0.623 (BinaryAccuracy: 0.676, BinaryAUROC: 0.676)  Valid loss: 0.635 (BinaryAccuracy: 0.616, BinaryAUROC: 0.6)\n",
      "|  Epoch 21: Train loss: 0.626 (BinaryAccuracy: 0.688, BinaryAUROC: 0.688)  Valid loss: 0.632 (BinaryAccuracy: 0.609, BinaryAUROC: 0.587)\n",
      "|  Epoch 22: Train loss: 0.626 (BinaryAccuracy: 0.679, BinaryAUROC: 0.679)  Valid loss: 0.634 (BinaryAccuracy: 0.623, BinaryAUROC: 0.603)\n",
      "|  Epoch 23: Train loss: 0.622 (BinaryAccuracy: 0.683, BinaryAUROC: 0.683)  Valid loss: 0.636 (BinaryAccuracy: 0.616, BinaryAUROC: 0.596)\n",
      "|  Epoch 24: Train loss: 0.617 (BinaryAccuracy: 0.675, BinaryAUROC: 0.673)  Valid loss: 0.64 (BinaryAccuracy: 0.623, BinaryAUROC: 0.605)\n",
      "|  Epoch 25: Train loss: 0.618 (BinaryAccuracy: 0.698, BinaryAUROC: 0.7)  Valid loss: 0.635 (BinaryAccuracy: 0.629, BinaryAUROC: 0.608)\n",
      "|  Epoch 26: Train loss: 0.615 (BinaryAccuracy: 0.693, BinaryAUROC: 0.692)  Valid loss: 0.635 (BinaryAccuracy: 0.623, BinaryAUROC: 0.602)\n",
      "|  Epoch 27: Train loss: 0.604 (BinaryAccuracy: 0.72, BinaryAUROC: 0.723)  Valid loss: 0.628 (BinaryAccuracy: 0.636, BinaryAUROC: 0.611)\n",
      "|  Epoch 28: Train loss: 0.612 (BinaryAccuracy: 0.694, BinaryAUROC: 0.692)  Valid loss: 0.628 (BinaryAccuracy: 0.629, BinaryAUROC: 0.603)\n",
      "|  Epoch 29: Train loss: 0.605 (BinaryAccuracy: 0.712, BinaryAUROC: 0.711)  Valid loss: 0.62 (BinaryAccuracy: 0.609, BinaryAUROC: 0.578)\n",
      "*  Epoch 30: Train loss: 0.611 (BinaryAccuracy: 0.707, BinaryAUROC: 0.71)  Valid loss: 0.628 (BinaryAccuracy: 0.642, BinaryAUROC: 0.624)\n",
      "|  Epoch 31: Train loss: 0.603 (BinaryAccuracy: 0.702, BinaryAUROC: 0.705)  Valid loss: 0.627 (BinaryAccuracy: 0.623, BinaryAUROC: 0.605)\n",
      "|  Epoch 32: Train loss: 0.608 (BinaryAccuracy: 0.697, BinaryAUROC: 0.694)  Valid loss: 0.628 (BinaryAccuracy: 0.616, BinaryAUROC: 0.599)\n",
      "|  Epoch 33: Train loss: 0.594 (BinaryAccuracy: 0.717, BinaryAUROC: 0.717)  Valid loss: 0.627 (BinaryAccuracy: 0.636, BinaryAUROC: 0.614)\n",
      "|  Epoch 34: Train loss: 0.604 (BinaryAccuracy: 0.69, BinaryAUROC: 0.692)  Valid loss: 0.633 (BinaryAccuracy: 0.609, BinaryAUROC: 0.596)\n",
      "|  Epoch 35: Train loss: 0.596 (BinaryAccuracy: 0.704, BinaryAUROC: 0.705)  Valid loss: 0.631 (BinaryAccuracy: 0.623, BinaryAUROC: 0.602)\n",
      "|  Epoch 36: Train loss: 0.589 (BinaryAccuracy: 0.73, BinaryAUROC: 0.73)  Valid loss: 0.631 (BinaryAccuracy: 0.629, BinaryAUROC: 0.605)\n",
      "|  Epoch 37: Train loss: 0.59 (BinaryAccuracy: 0.716, BinaryAUROC: 0.719)  Valid loss: 0.619 (BinaryAccuracy: 0.616, BinaryAUROC: 0.582)\n",
      "|  Epoch 38: Train loss: 0.589 (BinaryAccuracy: 0.704, BinaryAUROC: 0.704)  Valid loss: 0.604 (BinaryAccuracy: 0.623, BinaryAUROC: 0.593)\n",
      "|  Epoch 39: Train loss: 0.591 (BinaryAccuracy: 0.693, BinaryAUROC: 0.694)  Valid loss: 0.632 (BinaryAccuracy: 0.583, BinaryAUROC: 0.571)\n",
      "|  Epoch 40: Train loss: 0.588 (BinaryAccuracy: 0.707, BinaryAUROC: 0.707)  Valid loss: 0.611 (BinaryAccuracy: 0.596, BinaryAUROC: 0.572)\n",
      "|  Epoch 41: Train loss: 0.58 (BinaryAccuracy: 0.715, BinaryAUROC: 0.712)  Valid loss: 0.611 (BinaryAccuracy: 0.616, BinaryAUROC: 0.587)\n",
      "|  Epoch 42: Train loss: 0.567 (BinaryAccuracy: 0.738, BinaryAUROC: 0.739)  Valid loss: 0.602 (BinaryAccuracy: 0.609, BinaryAUROC: 0.57)\n",
      "|  Epoch 43: Train loss: 0.584 (BinaryAccuracy: 0.714, BinaryAUROC: 0.714)  Valid loss: 0.614 (BinaryAccuracy: 0.616, BinaryAUROC: 0.593)\n",
      "|  Epoch 44: Train loss: 0.581 (BinaryAccuracy: 0.721, BinaryAUROC: 0.72)  Valid loss: 0.618 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 45: Train loss: 0.573 (BinaryAccuracy: 0.707, BinaryAUROC: 0.706)  Valid loss: 0.632 (BinaryAccuracy: 0.583, BinaryAUROC: 0.571)\n",
      "|  Epoch 46: Train loss: 0.598 (BinaryAccuracy: 0.684, BinaryAUROC: 0.688)  Valid loss: 0.634 (BinaryAccuracy: 0.589, BinaryAUROC: 0.584)\n",
      "|  Epoch 47: Train loss: 0.586 (BinaryAccuracy: 0.704, BinaryAUROC: 0.706)  Valid loss: 0.613 (BinaryAccuracy: 0.603, BinaryAUROC: 0.585)\n",
      "|  Epoch 48: Train loss: 0.58 (BinaryAccuracy: 0.712, BinaryAUROC: 0.711)  Valid loss: 0.618 (BinaryAccuracy: 0.623, BinaryAUROC: 0.618)\n",
      "|  Epoch 49: Train loss: 0.57 (BinaryAccuracy: 0.745, BinaryAUROC: 0.747)  Valid loss: 0.603 (BinaryAccuracy: 0.603, BinaryAUROC: 0.59)\n",
      "|  Epoch 50: Train loss: 0.563 (BinaryAccuracy: 0.739, BinaryAUROC: 0.739)  Valid loss: 0.599 (BinaryAccuracy: 0.616, BinaryAUROC: 0.59)\n",
      "|  Epoch 51: Train loss: 0.572 (BinaryAccuracy: 0.73, BinaryAUROC: 0.73)  Valid loss: 0.61 (BinaryAccuracy: 0.629, BinaryAUROC: 0.618)\n",
      "|  Epoch 52: Train loss: 0.58 (BinaryAccuracy: 0.731, BinaryAUROC: 0.733)  Valid loss: 0.62 (BinaryAccuracy: 0.609, BinaryAUROC: 0.599)\n",
      "|  Epoch 53: Train loss: 0.57 (BinaryAccuracy: 0.736, BinaryAUROC: 0.735)  Valid loss: 0.614 (BinaryAccuracy: 0.609, BinaryAUROC: 0.594)\n",
      "|  Epoch 54: Train loss: 0.58 (BinaryAccuracy: 0.729, BinaryAUROC: 0.729)  Valid loss: 0.623 (BinaryAccuracy: 0.629, BinaryAUROC: 0.623)\n",
      "|  Epoch 55: Train loss: 0.575 (BinaryAccuracy: 0.732, BinaryAUROC: 0.732)  Valid loss: 0.606 (BinaryAccuracy: 0.609, BinaryAUROC: 0.59)\n",
      "|  Epoch 56: Train loss: 0.563 (BinaryAccuracy: 0.745, BinaryAUROC: 0.744)  Valid loss: 0.609 (BinaryAccuracy: 0.616, BinaryAUROC: 0.602)\n",
      "*  Epoch 57: Train loss: 0.586 (BinaryAccuracy: 0.737, BinaryAUROC: 0.738)  Valid loss: 0.611 (BinaryAccuracy: 0.642, BinaryAUROC: 0.635)\n",
      "|  Epoch 58: Train loss: 0.566 (BinaryAccuracy: 0.747, BinaryAUROC: 0.75)  Valid loss: 0.602 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 59: Train loss: 0.569 (BinaryAccuracy: 0.755, BinaryAUROC: 0.753)  Valid loss: 0.597 (BinaryAccuracy: 0.603, BinaryAUROC: 0.582)\n",
      "|  Epoch 60: Train loss: 0.553 (BinaryAccuracy: 0.769, BinaryAUROC: 0.768)  Valid loss: 0.599 (BinaryAccuracy: 0.636, BinaryAUROC: 0.612)\n",
      "|  Epoch 61: Train loss: 0.554 (BinaryAccuracy: 0.754, BinaryAUROC: 0.755)  Valid loss: 0.599 (BinaryAccuracy: 0.636, BinaryAUROC: 0.612)\n",
      "|  Epoch 62: Train loss: 0.566 (BinaryAccuracy: 0.739, BinaryAUROC: 0.739)  Valid loss: 0.609 (BinaryAccuracy: 0.596, BinaryAUROC: 0.584)\n",
      "|  Epoch 63: Train loss: 0.562 (BinaryAccuracy: 0.755, BinaryAUROC: 0.755)  Valid loss: 0.614 (BinaryAccuracy: 0.616, BinaryAUROC: 0.608)\n",
      "|  Epoch 64: Train loss: 0.575 (BinaryAccuracy: 0.737, BinaryAUROC: 0.738)  Valid loss: 0.631 (BinaryAccuracy: 0.616, BinaryAUROC: 0.626)\n",
      "|  Epoch 65: Train loss: 0.57 (BinaryAccuracy: 0.729, BinaryAUROC: 0.73)  Valid loss: 0.602 (BinaryAccuracy: 0.623, BinaryAUROC: 0.611)\n",
      "|  Epoch 66: Train loss: 0.547 (BinaryAccuracy: 0.747, BinaryAUROC: 0.746)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.591)\n",
      "|  Epoch 67: Train loss: 0.56 (BinaryAccuracy: 0.746, BinaryAUROC: 0.746)  Valid loss: 0.6 (BinaryAccuracy: 0.609, BinaryAUROC: 0.59)\n",
      "|  Epoch 68: Train loss: 0.576 (BinaryAccuracy: 0.721, BinaryAUROC: 0.721)  Valid loss: 0.6 (BinaryAccuracy: 0.616, BinaryAUROC: 0.602)\n",
      "|  Epoch 69: Train loss: 0.547 (BinaryAccuracy: 0.774, BinaryAUROC: 0.775)  Valid loss: 0.597 (BinaryAccuracy: 0.603, BinaryAUROC: 0.585)\n",
      "|  Epoch 70: Train loss: 0.555 (BinaryAccuracy: 0.744, BinaryAUROC: 0.744)  Valid loss: 0.603 (BinaryAccuracy: 0.616, BinaryAUROC: 0.606)\n",
      "|  Epoch 71: Train loss: 0.555 (BinaryAccuracy: 0.745, BinaryAUROC: 0.744)  Valid loss: 0.628 (BinaryAccuracy: 0.616, BinaryAUROC: 0.623)\n",
      "*  Epoch 72: Train loss: 0.564 (BinaryAccuracy: 0.75, BinaryAUROC: 0.752)  Valid loss: 0.609 (BinaryAccuracy: 0.642, BinaryAUROC: 0.638)\n",
      "|  Epoch 73: Train loss: 0.553 (BinaryAccuracy: 0.757, BinaryAUROC: 0.757)  Valid loss: 0.592 (BinaryAccuracy: 0.589, BinaryAUROC: 0.574)\n",
      "|  Epoch 74: Train loss: 0.559 (BinaryAccuracy: 0.736, BinaryAUROC: 0.738)  Valid loss: 0.595 (BinaryAccuracy: 0.589, BinaryAUROC: 0.572)\n",
      "|  Epoch 75: Train loss: 0.544 (BinaryAccuracy: 0.757, BinaryAUROC: 0.756)  Valid loss: 0.602 (BinaryAccuracy: 0.603, BinaryAUROC: 0.59)\n",
      "|  Epoch 76: Train loss: 0.55 (BinaryAccuracy: 0.742, BinaryAUROC: 0.744)  Valid loss: 0.616 (BinaryAccuracy: 0.609, BinaryAUROC: 0.608)\n",
      "|  Epoch 77: Train loss: 0.525 (BinaryAccuracy: 0.781, BinaryAUROC: 0.782)  Valid loss: 0.599 (BinaryAccuracy: 0.616, BinaryAUROC: 0.6)\n",
      "|  Epoch 78: Train loss: 0.554 (BinaryAccuracy: 0.745, BinaryAUROC: 0.745)  Valid loss: 0.603 (BinaryAccuracy: 0.623, BinaryAUROC: 0.617)\n",
      "|  Epoch 79: Train loss: 0.576 (BinaryAccuracy: 0.743, BinaryAUROC: 0.742)  Valid loss: 0.621 (BinaryAccuracy: 0.616, BinaryAUROC: 0.62)\n",
      "|  Epoch 80: Train loss: 0.559 (BinaryAccuracy: 0.74, BinaryAUROC: 0.74)  Valid loss: 0.61 (BinaryAccuracy: 0.623, BinaryAUROC: 0.618)\n",
      "|  Epoch 81: Train loss: 0.558 (BinaryAccuracy: 0.746, BinaryAUROC: 0.75)  Valid loss: 0.59 (BinaryAccuracy: 0.589, BinaryAUROC: 0.569)\n",
      "|  Epoch 82: Train loss: 0.546 (BinaryAccuracy: 0.751, BinaryAUROC: 0.751)  Valid loss: 0.594 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 83: Train loss: 0.547 (BinaryAccuracy: 0.754, BinaryAUROC: 0.753)  Valid loss: 0.6 (BinaryAccuracy: 0.629, BinaryAUROC: 0.621)\n",
      "|  Epoch 84: Train loss: 0.553 (BinaryAccuracy: 0.737, BinaryAUROC: 0.737)  Valid loss: 0.606 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 85: Train loss: 0.557 (BinaryAccuracy: 0.736, BinaryAUROC: 0.736)  Valid loss: 0.594 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 86: Train loss: 0.541 (BinaryAccuracy: 0.758, BinaryAUROC: 0.758)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.596)\n",
      "|  Epoch 87: Train loss: 0.563 (BinaryAccuracy: 0.743, BinaryAUROC: 0.744)  Valid loss: 0.607 (BinaryAccuracy: 0.623, BinaryAUROC: 0.62)\n",
      "|  Epoch 88: Train loss: 0.551 (BinaryAccuracy: 0.758, BinaryAUROC: 0.758)  Valid loss: 0.596 (BinaryAccuracy: 0.603, BinaryAUROC: 0.59)\n",
      "|  Epoch 89: Train loss: 0.535 (BinaryAccuracy: 0.769, BinaryAUROC: 0.767)  Valid loss: 0.598 (BinaryAccuracy: 0.629, BinaryAUROC: 0.621)\n",
      "|  Epoch 90: Train loss: 0.541 (BinaryAccuracy: 0.759, BinaryAUROC: 0.758)  Valid loss: 0.607 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 91: Train loss: 0.539 (BinaryAccuracy: 0.756, BinaryAUROC: 0.757)  Valid loss: 0.603 (BinaryAccuracy: 0.629, BinaryAUROC: 0.623)\n",
      "|  Epoch 92: Train loss: 0.536 (BinaryAccuracy: 0.771, BinaryAUROC: 0.773)  Valid loss: 0.593 (BinaryAccuracy: 0.603, BinaryAUROC: 0.584)\n",
      "|  Epoch 93: Train loss: 0.542 (BinaryAccuracy: 0.753, BinaryAUROC: 0.753)  Valid loss: 0.607 (BinaryAccuracy: 0.616, BinaryAUROC: 0.612)\n",
      "|  Epoch 94: Train loss: 0.559 (BinaryAccuracy: 0.755, BinaryAUROC: 0.755)  Valid loss: 0.626 (BinaryAccuracy: 0.629, BinaryAUROC: 0.636)\n",
      "|  Epoch 95: Train loss: 0.535 (BinaryAccuracy: 0.761, BinaryAUROC: 0.762)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.593)\n",
      "|  Epoch 96: Train loss: 0.547 (BinaryAccuracy: 0.751, BinaryAUROC: 0.753)  Valid loss: 0.594 (BinaryAccuracy: 0.623, BinaryAUROC: 0.612)\n",
      "|  Epoch 97: Train loss: 0.544 (BinaryAccuracy: 0.75, BinaryAUROC: 0.751)  Valid loss: 0.606 (BinaryAccuracy: 0.616, BinaryAUROC: 0.612)\n",
      "|  Epoch 98: Train loss: 0.544 (BinaryAccuracy: 0.758, BinaryAUROC: 0.759)  Valid loss: 0.596 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 99: Train loss: 0.534 (BinaryAccuracy: 0.763, BinaryAUROC: 0.763)  Valid loss: 0.597 (BinaryAccuracy: 0.583, BinaryAUROC: 0.569)\n",
      "*  Epoch 100: Train loss: 0.548 (BinaryAccuracy: 0.75, BinaryAUROC: 0.75)  Valid loss: 0.628 (BinaryAccuracy: 0.636, BinaryAUROC: 0.642)\n",
      "|  Epoch 101: Train loss: 0.558 (BinaryAccuracy: 0.745, BinaryAUROC: 0.744)  Valid loss: 0.602 (BinaryAccuracy: 0.616, BinaryAUROC: 0.608)\n",
      "|  Epoch 102: Train loss: 0.527 (BinaryAccuracy: 0.779, BinaryAUROC: 0.779)  Valid loss: 0.597 (BinaryAccuracy: 0.616, BinaryAUROC: 0.606)\n",
      "|  Epoch 103: Train loss: 0.549 (BinaryAccuracy: 0.754, BinaryAUROC: 0.757)  Valid loss: 0.589 (BinaryAccuracy: 0.603, BinaryAUROC: 0.581)\n",
      "|  Epoch 104: Train loss: 0.555 (BinaryAccuracy: 0.736, BinaryAUROC: 0.736)  Valid loss: 0.605 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 105: Train loss: 0.543 (BinaryAccuracy: 0.757, BinaryAUROC: 0.759)  Valid loss: 0.604 (BinaryAccuracy: 0.623, BinaryAUROC: 0.617)\n",
      "|  Epoch 106: Train loss: 0.548 (BinaryAccuracy: 0.763, BinaryAUROC: 0.764)  Valid loss: 0.594 (BinaryAccuracy: 0.596, BinaryAUROC: 0.583)\n",
      "|  Epoch 107: Train loss: 0.537 (BinaryAccuracy: 0.777, BinaryAUROC: 0.777)  Valid loss: 0.597 (BinaryAccuracy: 0.623, BinaryAUROC: 0.614)\n",
      "|  Epoch 108: Train loss: 0.538 (BinaryAccuracy: 0.755, BinaryAUROC: 0.756)  Valid loss: 0.6 (BinaryAccuracy: 0.589, BinaryAUROC: 0.578)\n",
      "|  Epoch 109: Train loss: 0.539 (BinaryAccuracy: 0.764, BinaryAUROC: 0.766)  Valid loss: 0.603 (BinaryAccuracy: 0.629, BinaryAUROC: 0.623)\n",
      "|  Epoch 110: Train loss: 0.547 (BinaryAccuracy: 0.754, BinaryAUROC: 0.754)  Valid loss: 0.602 (BinaryAccuracy: 0.596, BinaryAUROC: 0.584)\n",
      "|  Epoch 111: Train loss: 0.547 (BinaryAccuracy: 0.746, BinaryAUROC: 0.747)  Valid loss: 0.605 (BinaryAccuracy: 0.623, BinaryAUROC: 0.618)\n",
      "|  Epoch 112: Train loss: 0.533 (BinaryAccuracy: 0.776, BinaryAUROC: 0.776)  Valid loss: 0.599 (BinaryAccuracy: 0.609, BinaryAUROC: 0.6)\n",
      "|  Epoch 113: Train loss: 0.533 (BinaryAccuracy: 0.769, BinaryAUROC: 0.771)  Valid loss: 0.588 (BinaryAccuracy: 0.596, BinaryAUROC: 0.578)\n",
      "|  Epoch 114: Train loss: 0.544 (BinaryAccuracy: 0.746, BinaryAUROC: 0.746)  Valid loss: 0.614 (BinaryAccuracy: 0.616, BinaryAUROC: 0.614)\n",
      "|  Epoch 115: Train loss: 0.527 (BinaryAccuracy: 0.775, BinaryAUROC: 0.777)  Valid loss: 0.593 (BinaryAccuracy: 0.609, BinaryAUROC: 0.597)\n",
      "|  Epoch 116: Train loss: 0.541 (BinaryAccuracy: 0.768, BinaryAUROC: 0.771)  Valid loss: 0.605 (BinaryAccuracy: 0.616, BinaryAUROC: 0.612)\n",
      "|  Epoch 117: Train loss: 0.545 (BinaryAccuracy: 0.759, BinaryAUROC: 0.759)  Valid loss: 0.602 (BinaryAccuracy: 0.609, BinaryAUROC: 0.602)\n",
      "|  Epoch 118: Train loss: 0.53 (BinaryAccuracy: 0.774, BinaryAUROC: 0.775)  Valid loss: 0.595 (BinaryAccuracy: 0.596, BinaryAUROC: 0.584)\n",
      "|  Epoch 119: Train loss: 0.539 (BinaryAccuracy: 0.772, BinaryAUROC: 0.773)  Valid loss: 0.591 (BinaryAccuracy: 0.583, BinaryAUROC: 0.565)\n",
      "|  Epoch 120: Train loss: 0.536 (BinaryAccuracy: 0.771, BinaryAUROC: 0.771)  Valid loss: 0.599 (BinaryAccuracy: 0.603, BinaryAUROC: 0.596)\n",
      "|  Epoch 121: Train loss: 0.531 (BinaryAccuracy: 0.76, BinaryAUROC: 0.761)  Valid loss: 0.602 (BinaryAccuracy: 0.596, BinaryAUROC: 0.592)\n",
      "|  Epoch 122: Train loss: 0.529 (BinaryAccuracy: 0.758, BinaryAUROC: 0.758)  Valid loss: 0.604 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 123: Train loss: 0.508 (BinaryAccuracy: 0.811, BinaryAUROC: 0.809)  Valid loss: 0.589 (BinaryAccuracy: 0.616, BinaryAUROC: 0.593)\n",
      "|  Epoch 124: Train loss: 0.541 (BinaryAccuracy: 0.764, BinaryAUROC: 0.766)  Valid loss: 0.605 (BinaryAccuracy: 0.589, BinaryAUROC: 0.584)\n",
      "|  Epoch 125: Train loss: 0.526 (BinaryAccuracy: 0.784, BinaryAUROC: 0.784)  Valid loss: 0.603 (BinaryAccuracy: 0.583, BinaryAUROC: 0.577)\n",
      "|  Epoch 126: Train loss: 0.527 (BinaryAccuracy: 0.77, BinaryAUROC: 0.771)  Valid loss: 0.598 (BinaryAccuracy: 0.589, BinaryAUROC: 0.583)\n",
      "|  Epoch 127: Train loss: 0.539 (BinaryAccuracy: 0.769, BinaryAUROC: 0.768)  Valid loss: 0.615 (BinaryAccuracy: 0.616, BinaryAUROC: 0.615)\n",
      "|  Epoch 128: Train loss: 0.527 (BinaryAccuracy: 0.789, BinaryAUROC: 0.788)  Valid loss: 0.589 (BinaryAccuracy: 0.589, BinaryAUROC: 0.575)\n",
      "|  Epoch 129: Train loss: 0.538 (BinaryAccuracy: 0.791, BinaryAUROC: 0.79)  Valid loss: 0.605 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 130: Train loss: 0.532 (BinaryAccuracy: 0.763, BinaryAUROC: 0.762)  Valid loss: 0.594 (BinaryAccuracy: 0.576, BinaryAUROC: 0.562)\n",
      "|  Epoch 131: Train loss: 0.563 (BinaryAccuracy: 0.75, BinaryAUROC: 0.751)  Valid loss: 0.618 (BinaryAccuracy: 0.616, BinaryAUROC: 0.615)\n",
      "|  Epoch 132: Train loss: 0.542 (BinaryAccuracy: 0.751, BinaryAUROC: 0.752)  Valid loss: 0.599 (BinaryAccuracy: 0.603, BinaryAUROC: 0.595)\n",
      "|  Epoch 133: Train loss: 0.533 (BinaryAccuracy: 0.774, BinaryAUROC: 0.778)  Valid loss: 0.587 (BinaryAccuracy: 0.603, BinaryAUROC: 0.584)\n",
      "|  Epoch 134: Train loss: 0.524 (BinaryAccuracy: 0.761, BinaryAUROC: 0.761)  Valid loss: 0.597 (BinaryAccuracy: 0.57, BinaryAUROC: 0.556)\n",
      "|  Epoch 135: Train loss: 0.527 (BinaryAccuracy: 0.785, BinaryAUROC: 0.784)  Valid loss: 0.613 (BinaryAccuracy: 0.616, BinaryAUROC: 0.615)\n",
      "|  Epoch 136: Train loss: 0.529 (BinaryAccuracy: 0.773, BinaryAUROC: 0.774)  Valid loss: 0.594 (BinaryAccuracy: 0.609, BinaryAUROC: 0.599)\n",
      "|  Epoch 137: Train loss: 0.526 (BinaryAccuracy: 0.774, BinaryAUROC: 0.776)  Valid loss: 0.601 (BinaryAccuracy: 0.583, BinaryAUROC: 0.577)\n",
      "|  Epoch 138: Train loss: 0.517 (BinaryAccuracy: 0.769, BinaryAUROC: 0.769)  Valid loss: 0.6 (BinaryAccuracy: 0.589, BinaryAUROC: 0.583)\n",
      "|  Epoch 139: Train loss: 0.53 (BinaryAccuracy: 0.775, BinaryAUROC: 0.775)  Valid loss: 0.593 (BinaryAccuracy: 0.576, BinaryAUROC: 0.563)\n",
      "|  Epoch 140: Train loss: 0.547 (BinaryAccuracy: 0.764, BinaryAUROC: 0.764)  Valid loss: 0.595 (BinaryAccuracy: 0.596, BinaryAUROC: 0.59)\n",
      "|  Epoch 141: Train loss: 0.525 (BinaryAccuracy: 0.769, BinaryAUROC: 0.769)  Valid loss: 0.61 (BinaryAccuracy: 0.623, BinaryAUROC: 0.621)\n",
      "|  Epoch 142: Train loss: 0.524 (BinaryAccuracy: 0.774, BinaryAUROC: 0.773)  Valid loss: 0.602 (BinaryAccuracy: 0.603, BinaryAUROC: 0.599)\n",
      "|  Epoch 143: Train loss: 0.526 (BinaryAccuracy: 0.775, BinaryAUROC: 0.775)  Valid loss: 0.605 (BinaryAccuracy: 0.603, BinaryAUROC: 0.599)\n",
      "|  Epoch 144: Train loss: 0.535 (BinaryAccuracy: 0.79, BinaryAUROC: 0.79)  Valid loss: 0.598 (BinaryAccuracy: 0.596, BinaryAUROC: 0.59)\n",
      "|  Epoch 145: Train loss: 0.539 (BinaryAccuracy: 0.764, BinaryAUROC: 0.764)  Valid loss: 0.608 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 146: Train loss: 0.532 (BinaryAccuracy: 0.766, BinaryAUROC: 0.766)  Valid loss: 0.606 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 147: Train loss: 0.52 (BinaryAccuracy: 0.782, BinaryAUROC: 0.783)  Valid loss: 0.597 (BinaryAccuracy: 0.596, BinaryAUROC: 0.587)\n",
      "|  Epoch 148: Train loss: 0.523 (BinaryAccuracy: 0.775, BinaryAUROC: 0.775)  Valid loss: 0.604 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 149: Train loss: 0.511 (BinaryAccuracy: 0.778, BinaryAUROC: 0.776)  Valid loss: 0.599 (BinaryAccuracy: 0.603, BinaryAUROC: 0.598)\n",
      "|  Epoch 150: Train loss: 0.521 (BinaryAccuracy: 0.775, BinaryAUROC: 0.774)  Valid loss: 0.594 (BinaryAccuracy: 0.596, BinaryAUROC: 0.58)\n",
      "|  Epoch 151: Train loss: 0.524 (BinaryAccuracy: 0.774, BinaryAUROC: 0.772)  Valid loss: 0.601 (BinaryAccuracy: 0.589, BinaryAUROC: 0.584)\n",
      "|  Epoch 152: Train loss: 0.516 (BinaryAccuracy: 0.768, BinaryAUROC: 0.769)  Valid loss: 0.601 (BinaryAccuracy: 0.603, BinaryAUROC: 0.596)\n",
      "|  Epoch 153: Train loss: 0.525 (BinaryAccuracy: 0.763, BinaryAUROC: 0.764)  Valid loss: 0.616 (BinaryAccuracy: 0.629, BinaryAUROC: 0.629)\n",
      "|  Epoch 154: Train loss: 0.523 (BinaryAccuracy: 0.785, BinaryAUROC: 0.785)  Valid loss: 0.591 (BinaryAccuracy: 0.603, BinaryAUROC: 0.592)\n",
      "|  Epoch 155: Train loss: 0.518 (BinaryAccuracy: 0.79, BinaryAUROC: 0.791)  Valid loss: 0.597 (BinaryAccuracy: 0.603, BinaryAUROC: 0.598)\n",
      "|  Epoch 156: Train loss: 0.518 (BinaryAccuracy: 0.769, BinaryAUROC: 0.77)  Valid loss: 0.601 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 157: Train loss: 0.515 (BinaryAccuracy: 0.783, BinaryAUROC: 0.783)  Valid loss: 0.591 (BinaryAccuracy: 0.589, BinaryAUROC: 0.575)\n",
      "|  Epoch 158: Train loss: 0.531 (BinaryAccuracy: 0.78, BinaryAUROC: 0.781)  Valid loss: 0.605 (BinaryAccuracy: 0.623, BinaryAUROC: 0.62)\n",
      "|  Epoch 159: Train loss: 0.517 (BinaryAccuracy: 0.781, BinaryAUROC: 0.782)  Valid loss: 0.59 (BinaryAccuracy: 0.616, BinaryAUROC: 0.596)\n",
      "|  Epoch 160: Train loss: 0.532 (BinaryAccuracy: 0.765, BinaryAUROC: 0.764)  Valid loss: 0.601 (BinaryAccuracy: 0.603, BinaryAUROC: 0.595)\n",
      "|  Epoch 161: Train loss: 0.531 (BinaryAccuracy: 0.769, BinaryAUROC: 0.769)  Valid loss: 0.613 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 162: Train loss: 0.51 (BinaryAccuracy: 0.793, BinaryAUROC: 0.794)  Valid loss: 0.598 (BinaryAccuracy: 0.609, BinaryAUROC: 0.602)\n",
      "|  Epoch 163: Train loss: 0.522 (BinaryAccuracy: 0.784, BinaryAUROC: 0.784)  Valid loss: 0.596 (BinaryAccuracy: 0.616, BinaryAUROC: 0.605)\n",
      "|  Epoch 164: Train loss: 0.52 (BinaryAccuracy: 0.773, BinaryAUROC: 0.773)  Valid loss: 0.597 (BinaryAccuracy: 0.596, BinaryAUROC: 0.587)\n",
      "|  Epoch 165: Train loss: 0.508 (BinaryAccuracy: 0.787, BinaryAUROC: 0.788)  Valid loss: 0.595 (BinaryAccuracy: 0.609, BinaryAUROC: 0.6)\n",
      "|  Epoch 166: Train loss: 0.502 (BinaryAccuracy: 0.782, BinaryAUROC: 0.781)  Valid loss: 0.598 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 167: Train loss: 0.521 (BinaryAccuracy: 0.793, BinaryAUROC: 0.793)  Valid loss: 0.606 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 168: Train loss: 0.514 (BinaryAccuracy: 0.791, BinaryAUROC: 0.791)  Valid loss: 0.599 (BinaryAccuracy: 0.603, BinaryAUROC: 0.599)\n",
      "|  Epoch 169: Train loss: 0.517 (BinaryAccuracy: 0.787, BinaryAUROC: 0.788)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 170: Train loss: 0.524 (BinaryAccuracy: 0.769, BinaryAUROC: 0.769)  Valid loss: 0.596 (BinaryAccuracy: 0.596, BinaryAUROC: 0.592)\n",
      "|  Epoch 171: Train loss: 0.501 (BinaryAccuracy: 0.808, BinaryAUROC: 0.809)  Valid loss: 0.597 (BinaryAccuracy: 0.596, BinaryAUROC: 0.59)\n",
      "|  Epoch 172: Train loss: 0.528 (BinaryAccuracy: 0.78, BinaryAUROC: 0.781)  Valid loss: 0.611 (BinaryAccuracy: 0.616, BinaryAUROC: 0.615)\n",
      "|  Epoch 173: Train loss: 0.515 (BinaryAccuracy: 0.779, BinaryAUROC: 0.78)  Valid loss: 0.593 (BinaryAccuracy: 0.609, BinaryAUROC: 0.602)\n",
      "|  Epoch 174: Train loss: 0.523 (BinaryAccuracy: 0.779, BinaryAUROC: 0.779)  Valid loss: 0.595 (BinaryAccuracy: 0.596, BinaryAUROC: 0.589)\n",
      "|  Epoch 175: Train loss: 0.516 (BinaryAccuracy: 0.779, BinaryAUROC: 0.778)  Valid loss: 0.591 (BinaryAccuracy: 0.589, BinaryAUROC: 0.578)\n",
      "|  Epoch 176: Train loss: 0.518 (BinaryAccuracy: 0.781, BinaryAUROC: 0.78)  Valid loss: 0.611 (BinaryAccuracy: 0.623, BinaryAUROC: 0.621)\n",
      "|  Epoch 177: Train loss: 0.495 (BinaryAccuracy: 0.807, BinaryAUROC: 0.806)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.605)\n",
      "|  Epoch 178: Train loss: 0.538 (BinaryAccuracy: 0.768, BinaryAUROC: 0.767)  Valid loss: 0.602 (BinaryAccuracy: 0.596, BinaryAUROC: 0.59)\n",
      "|  Epoch 179: Train loss: 0.516 (BinaryAccuracy: 0.783, BinaryAUROC: 0.782)  Valid loss: 0.602 (BinaryAccuracy: 0.603, BinaryAUROC: 0.599)\n",
      "|  Epoch 180: Train loss: 0.5 (BinaryAccuracy: 0.8, BinaryAUROC: 0.799)  Valid loss: 0.59 (BinaryAccuracy: 0.609, BinaryAUROC: 0.599)\n",
      "|  Epoch 181: Train loss: 0.497 (BinaryAccuracy: 0.803, BinaryAUROC: 0.804)  Valid loss: 0.588 (BinaryAccuracy: 0.609, BinaryAUROC: 0.597)\n",
      "|  Epoch 182: Train loss: 0.545 (BinaryAccuracy: 0.765, BinaryAUROC: 0.765)  Valid loss: 0.636 (BinaryAccuracy: 0.609, BinaryAUROC: 0.62)\n",
      "|  Epoch 183: Train loss: 0.525 (BinaryAccuracy: 0.755, BinaryAUROC: 0.755)  Valid loss: 0.6 (BinaryAccuracy: 0.616, BinaryAUROC: 0.614)\n",
      "|  Epoch 184: Train loss: 0.52 (BinaryAccuracy: 0.772, BinaryAUROC: 0.772)  Valid loss: 0.592 (BinaryAccuracy: 0.576, BinaryAUROC: 0.563)\n",
      "|  Epoch 185: Train loss: 0.5 (BinaryAccuracy: 0.789, BinaryAUROC: 0.788)  Valid loss: 0.608 (BinaryAccuracy: 0.616, BinaryAUROC: 0.614)\n",
      "|  Epoch 186: Train loss: 0.52 (BinaryAccuracy: 0.783, BinaryAUROC: 0.783)  Valid loss: 0.595 (BinaryAccuracy: 0.609, BinaryAUROC: 0.607)\n",
      "|  Epoch 187: Train loss: 0.502 (BinaryAccuracy: 0.79, BinaryAUROC: 0.788)  Valid loss: 0.589 (BinaryAccuracy: 0.596, BinaryAUROC: 0.583)\n",
      "|  Epoch 188: Train loss: 0.51 (BinaryAccuracy: 0.781, BinaryAUROC: 0.782)  Valid loss: 0.608 (BinaryAccuracy: 0.616, BinaryAUROC: 0.614)\n",
      "|  Epoch 189: Train loss: 0.519 (BinaryAccuracy: 0.777, BinaryAUROC: 0.778)  Valid loss: 0.608 (BinaryAccuracy: 0.623, BinaryAUROC: 0.621)\n",
      "|  Epoch 190: Train loss: 0.515 (BinaryAccuracy: 0.791, BinaryAUROC: 0.79)  Valid loss: 0.597 (BinaryAccuracy: 0.623, BinaryAUROC: 0.62)\n",
      "|  Epoch 191: Train loss: 0.52 (BinaryAccuracy: 0.78, BinaryAUROC: 0.781)  Valid loss: 0.598 (BinaryAccuracy: 0.623, BinaryAUROC: 0.62)\n",
      "|  Epoch 192: Train loss: 0.519 (BinaryAccuracy: 0.777, BinaryAUROC: 0.776)  Valid loss: 0.618 (BinaryAccuracy: 0.636, BinaryAUROC: 0.638)\n",
      "|  Epoch 193: Train loss: 0.502 (BinaryAccuracy: 0.791, BinaryAUROC: 0.792)  Valid loss: 0.588 (BinaryAccuracy: 0.609, BinaryAUROC: 0.593)\n",
      "|  Epoch 194: Train loss: 0.509 (BinaryAccuracy: 0.797, BinaryAUROC: 0.798)  Valid loss: 0.587 (BinaryAccuracy: 0.603, BinaryAUROC: 0.587)\n",
      "|  Epoch 195: Train loss: 0.513 (BinaryAccuracy: 0.785, BinaryAUROC: 0.785)  Valid loss: 0.602 (BinaryAccuracy: 0.616, BinaryAUROC: 0.612)\n",
      "|  Epoch 196: Train loss: 0.492 (BinaryAccuracy: 0.809, BinaryAUROC: 0.808)  Valid loss: 0.597 (BinaryAccuracy: 0.609, BinaryAUROC: 0.604)\n",
      "|  Epoch 197: Train loss: 0.519 (BinaryAccuracy: 0.783, BinaryAUROC: 0.783)  Valid loss: 0.602 (BinaryAccuracy: 0.623, BinaryAUROC: 0.62)\n",
      "|  Epoch 198: Train loss: 0.513 (BinaryAccuracy: 0.8, BinaryAUROC: 0.799)  Valid loss: 0.594 (BinaryAccuracy: 0.603, BinaryAUROC: 0.599)\n",
      "|  Epoch 199: Train loss: 0.5 (BinaryAccuracy: 0.789, BinaryAUROC: 0.79)  Valid loss: 0.59 (BinaryAccuracy: 0.596, BinaryAUROC: 0.586)\n",
      "|  Epoch 200: Train loss: 0.52 (BinaryAccuracy: 0.772, BinaryAUROC: 0.772)  Valid loss: 0.609 (BinaryAccuracy: 0.609, BinaryAUROC: 0.608)\n",
      "------------------------------------------------\n",
      "Using Epoch 100 for testing...\n",
      "Test loss: 0.605\n",
      "Test BinaryAccuracy: 0.691\n",
      "Test BinaryAUROC: 0.71\n"
     ]
    }
   ],
   "source": [
    "d = 44\n",
    "model = SetRepClassifier(100, 16, d, 2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [BinaryAccuracy(), BinaryAUROC()],\n",
    "    [BinaryAccuracy(), BinaryAUROC()],\n",
    "    [BinaryAccuracy(), BinaryAUROC()],\n",
    "    # scheduler=scheduler,\n",
    "    monitor_metric=1,\n",
    "    monitor_lower_is_better=False\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daenu/miniconda3/envs/molsetrep/lib/python3.9/site-packages/deepchem/feat/molecule_featurizers/coulomb_matrices.py:145: RuntimeWarning: divide by zero encountered in divide\n",
      "  m = np.outer(z, z) / d\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bond_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train, valid, test \u001b[39m=\u001b[39m molnet_loader(\u001b[39m\"\u001b[39m\u001b[39mqm7\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_loader, valid_loader, test_loader \u001b[39m=\u001b[39m molnet_to_pyg(train, valid, test, label_type\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat)\n\u001b[1;32m      4\u001b[0m num_node_features \u001b[39m=\u001b[39m train_loader\u001b[39m.\u001b[39mdataset[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnum_node_features\n\u001b[1;32m      5\u001b[0m num_edge_features \u001b[39m=\u001b[39m train_loader\u001b[39m.\u001b[39mdataset[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnum_edge_features\n",
      "File \u001b[0;32m~/code/molsetrep/src/molsetrep/utils/converters.py:219\u001b[0m, in \u001b[0;36mmolnet_to_pyg\u001b[0;34m(train, valid, test, task, batch_size, atom_attrs, bond_attrs, suppress_rdkit_warnings, label_type)\u001b[0m\n\u001b[1;32m    216\u001b[0m train_data_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m i, G \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m([smiles_to_nx(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m train\u001b[39m.\u001b[39mids]):\n\u001b[1;32m    218\u001b[0m     train_data_list\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 219\u001b[0m         nx_to_pyg(\n\u001b[1;32m    220\u001b[0m             G,\n\u001b[1;32m    221\u001b[0m             group_node_attrs\u001b[39m=\u001b[39;49matom_attrs,\n\u001b[1;32m    222\u001b[0m             group_edge_attrs\u001b[39m=\u001b[39;49mbond_attrs,\n\u001b[1;32m    223\u001b[0m             y\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([train\u001b[39m.\u001b[39;49my[i][task]], dtype\u001b[39m=\u001b[39;49mlabel_type),\n\u001b[1;32m    224\u001b[0m         )\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m valid_data_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    228\u001b[0m \u001b[39mfor\u001b[39;00m i, G \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m([smiles_to_nx(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m valid\u001b[39m.\u001b[39mids]):\n",
      "File \u001b[0;32m~/code/molsetrep/src/molsetrep/utils/converters.py:167\u001b[0m, in \u001b[0;36mnx_to_pyg\u001b[0;34m(G, group_node_attrs, group_edge_attrs, y)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m group_edge_attrs:\n\u001b[1;32m    166\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39medge_\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m node_attrs \u001b[39melse\u001b[39;00m key\n\u001b[0;32m--> 167\u001b[0m     x \u001b[39m=\u001b[39m data[key]\n\u001b[1;32m    168\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdim() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    169\u001b[0m     xs\u001b[39m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/molsetrep/lib/python3.9/site-packages/torch_geometric/data/data.py:457\u001b[0m, in \u001b[0;36mData.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/molsetrep/lib/python3.9/site-packages/torch_geometric/data/storage.py:104\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bond_type'"
     ]
    }
   ],
   "source": [
    "train, valid, test = molnet_loader(\"lipo\")\n",
    "train_loader, valid_loader, test_loader = molnet_to_pyg(train, valid, test, label_type=torch.float)\n",
    "\n",
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNSetRepRegressor(num_node_features, 256, 2, num_edge_features, 100, 16)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [R2Score(), RootMeanSquaredError()],\n",
    "    [R2Score(), RootMeanSquaredError()],\n",
    "    [R2Score(), RootMeanSquaredError()],\n",
    "    monitor_metric=1\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
