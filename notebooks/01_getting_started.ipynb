{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchmetrics.classification import Accuracy, AUROC\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError\n",
    "\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "from molsetrep.utils.trainer import Trainer\n",
    "from molsetrep.utils.datasets import molnet_loader\n",
    "from molsetrep.utils.converters import molnet_to_pyg, smiles_to_nx, nx_to_pyg\n",
    "from molsetrep.utils.root_mean_squared_error import RootMeanSquaredError\n",
    "from molsetrep.models import GNNSetRepClassifier, GNNSetRepRegressor, GNNSetRepClassifierSubstruct, GNNRegressor, GNNClassifier\n",
    "from molsetrep.explain import RegressionExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], atomic_num=[4], charge=[4], aromatic=[4], is_in_ring=[4], hydrogen_count=[4], hybridization_sp=[4], hybridization_sp2=[4], hybridization_sp3=[4], hybridization_sp3d=[4], hybridization_sp3d2=[4], chiral_type_chi_tetrahedral_cw=[4], chiral_type_chi_tetrahedral_ccw=[4], chiral_type_chi_other=[4], chiral_type_chi_tetrahedral=[4], chiral_type_chi_allene=[4], chiral_type_chi_squareplanar=[4], chiral_type_chi_trigonalbipyramidal=[4], chiral_type_chi_octahedral=[4], degree=[4], radical_count=[4], bond_type=[4], bond_type_aromatic=[4], bond_conjugated=[4], bond_stereo_z=[4], bond_stereo_e=[4], bond_stereo_cis=[4], bond_stereo_trans=[4], num_nodes=4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx_to_pyg(smiles_to_nx(\"C.CNC\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:53:07] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 59, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 61, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 391, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 614, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 12 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 642, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 645, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 646, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 647, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 648, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 649, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "Failed to featurize datapoint 685, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True)\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "/home/daenu/miniconda3/envs/molsetrep/lib/python3.10/site-packages/deepchem/feat/base_classes.py:323: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(features)\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[21:53:08] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Compare to https://github.com/chemprop/chemprop\n",
    "train, valid, test = molnet_loader(\"bbbp\", reload=False)\n",
    "train_loader, valid_loader, test_loader = molnet_to_pyg(\n",
    "    train,\n",
    "    valid,\n",
    "    test,\n",
    "    label_type=torch.long,\n",
    "    imbalanced_sampler=True,\n",
    "    secfp=False,\n",
    "    index_graphs=False,\n",
    "    # atom_attrs=[\"atomic_num\", \"charge\", \"hydrogen_count\"],\n",
    "    # bond_attrs=[\"bond_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Epoch 1: Train loss: 0.653 (BinaryAccuracy: 0.633, BinaryAUROC: 0.627)  Valid loss: 0.564 (BinaryAccuracy: 0.781, BinaryAUROC: 0.77)\n",
      "*  Epoch 2: Train loss: 0.61 (BinaryAccuracy: 0.678, BinaryAUROC: 0.672)  Valid loss: 0.53 (BinaryAccuracy: 0.807, BinaryAUROC: 0.794)\n",
      "*  Epoch 3: Train loss: 0.606 (BinaryAccuracy: 0.675, BinaryAUROC: 0.673)  Valid loss: 0.484 (BinaryAccuracy: 0.844, BinaryAUROC: 0.837)\n",
      "|  Epoch 4: Train loss: 0.586 (BinaryAccuracy: 0.686, BinaryAUROC: 0.688)  Valid loss: 0.559 (BinaryAccuracy: 0.807, BinaryAUROC: 0.798)\n",
      "|  Epoch 5: Train loss: 0.586 (BinaryAccuracy: 0.706, BinaryAUROC: 0.702)  Valid loss: 0.496 (BinaryAccuracy: 0.807, BinaryAUROC: 0.797)\n",
      "|  Epoch 6: Train loss: 0.588 (BinaryAccuracy: 0.693, BinaryAUROC: 0.691)  Valid loss: 0.506 (BinaryAccuracy: 0.87, BinaryAUROC: 0.862)\n",
      "*  Epoch 7: Train loss: 0.581 (BinaryAccuracy: 0.683, BinaryAUROC: 0.684)  Valid loss: 0.448 (BinaryAccuracy: 0.823, BinaryAUROC: 0.813)\n",
      "*  Epoch 8: Train loss: 0.549 (BinaryAccuracy: 0.707, BinaryAUROC: 0.713)  Valid loss: 0.408 (BinaryAccuracy: 0.87, BinaryAUROC: 0.858)\n",
      "*  Epoch 9: Train loss: 0.554 (BinaryAccuracy: 0.712, BinaryAUROC: 0.711)  Valid loss: 0.407 (BinaryAccuracy: 0.885, BinaryAUROC: 0.88)\n",
      "|  Epoch 10: Train loss: 0.538 (BinaryAccuracy: 0.729, BinaryAUROC: 0.728)  Valid loss: 0.436 (BinaryAccuracy: 0.849, BinaryAUROC: 0.84)\n",
      "|  Epoch 11: Train loss: 0.534 (BinaryAccuracy: 0.729, BinaryAUROC: 0.738)  Valid loss: 0.441 (BinaryAccuracy: 0.875, BinaryAUROC: 0.868)\n",
      "|  Epoch 12: Train loss: 0.53 (BinaryAccuracy: 0.736, BinaryAUROC: 0.735)  Valid loss: 0.437 (BinaryAccuracy: 0.865, BinaryAUROC: 0.858)\n",
      "*  Epoch 13: Train loss: 0.529 (BinaryAccuracy: 0.743, BinaryAUROC: 0.744)  Valid loss: 0.4 (BinaryAccuracy: 0.87, BinaryAUROC: 0.859)\n",
      "*  Epoch 14: Train loss: 0.512 (BinaryAccuracy: 0.749, BinaryAUROC: 0.749)  Valid loss: 0.361 (BinaryAccuracy: 0.865, BinaryAUROC: 0.858)\n",
      "|  Epoch 15: Train loss: 0.496 (BinaryAccuracy: 0.756, BinaryAUROC: 0.756)  Valid loss: 0.366 (BinaryAccuracy: 0.885, BinaryAUROC: 0.878)\n",
      "*  Epoch 16: Train loss: 0.519 (BinaryAccuracy: 0.743, BinaryAUROC: 0.742)  Valid loss: 0.342 (BinaryAccuracy: 0.896, BinaryAUROC: 0.89)\n",
      "|  Epoch 17: Train loss: 0.522 (BinaryAccuracy: 0.728, BinaryAUROC: 0.729)  Valid loss: 0.385 (BinaryAccuracy: 0.87, BinaryAUROC: 0.86)\n",
      "|  Epoch 18: Train loss: 0.522 (BinaryAccuracy: 0.744, BinaryAUROC: 0.742)  Valid loss: 0.357 (BinaryAccuracy: 0.87, BinaryAUROC: 0.864)\n",
      "|  Epoch 19: Train loss: 0.486 (BinaryAccuracy: 0.755, BinaryAUROC: 0.757)  Valid loss: 0.364 (BinaryAccuracy: 0.885, BinaryAUROC: 0.879)\n",
      "*  Epoch 20: Train loss: 0.476 (BinaryAccuracy: 0.757, BinaryAUROC: 0.76)  Valid loss: 0.339 (BinaryAccuracy: 0.891, BinaryAUROC: 0.886)\n",
      "|  Epoch 21: Train loss: 0.465 (BinaryAccuracy: 0.774, BinaryAUROC: 0.78)  Valid loss: 0.362 (BinaryAccuracy: 0.87, BinaryAUROC: 0.866)\n",
      "|  Epoch 22: Train loss: 0.455 (BinaryAccuracy: 0.786, BinaryAUROC: 0.788)  Valid loss: 0.366 (BinaryAccuracy: 0.875, BinaryAUROC: 0.871)\n",
      "|  Epoch 23: Train loss: 0.458 (BinaryAccuracy: 0.799, BinaryAUROC: 0.801)  Valid loss: 0.343 (BinaryAccuracy: 0.896, BinaryAUROC: 0.892)\n",
      "|  Epoch 24: Train loss: 0.445 (BinaryAccuracy: 0.797, BinaryAUROC: 0.794)  Valid loss: 0.347 (BinaryAccuracy: 0.891, BinaryAUROC: 0.884)\n",
      "|  Epoch 25: Train loss: 0.451 (BinaryAccuracy: 0.793, BinaryAUROC: 0.793)  Valid loss: 0.357 (BinaryAccuracy: 0.854, BinaryAUROC: 0.851)\n",
      "|  Epoch 26: Train loss: 0.453 (BinaryAccuracy: 0.784, BinaryAUROC: 0.781)  Valid loss: 0.364 (BinaryAccuracy: 0.849, BinaryAUROC: 0.85)\n",
      "*  Epoch 27: Train loss: 0.446 (BinaryAccuracy: 0.797, BinaryAUROC: 0.798)  Valid loss: 0.327 (BinaryAccuracy: 0.906, BinaryAUROC: 0.906)\n",
      "*  Epoch 28: Train loss: 0.441 (BinaryAccuracy: 0.794, BinaryAUROC: 0.794)  Valid loss: 0.314 (BinaryAccuracy: 0.896, BinaryAUROC: 0.89)\n",
      "*  Epoch 29: Train loss: 0.421 (BinaryAccuracy: 0.801, BinaryAUROC: 0.799)  Valid loss: 0.314 (BinaryAccuracy: 0.885, BinaryAUROC: 0.881)\n",
      "|  Epoch 30: Train loss: 0.429 (BinaryAccuracy: 0.809, BinaryAUROC: 0.81)  Valid loss: 0.368 (BinaryAccuracy: 0.839, BinaryAUROC: 0.836)\n",
      "|  Epoch 31: Train loss: 0.47 (BinaryAccuracy: 0.769, BinaryAUROC: 0.769)  Valid loss: 0.336 (BinaryAccuracy: 0.865, BinaryAUROC: 0.865)\n",
      "|  Epoch 32: Train loss: 0.421 (BinaryAccuracy: 0.805, BinaryAUROC: 0.804)  Valid loss: 0.325 (BinaryAccuracy: 0.901, BinaryAUROC: 0.896)\n",
      "|  Epoch 33: Train loss: 0.439 (BinaryAccuracy: 0.788, BinaryAUROC: 0.786)  Valid loss: 0.356 (BinaryAccuracy: 0.849, BinaryAUROC: 0.843)\n",
      "|  Epoch 34: Train loss: 0.436 (BinaryAccuracy: 0.791, BinaryAUROC: 0.791)  Valid loss: 0.335 (BinaryAccuracy: 0.87, BinaryAUROC: 0.869)\n",
      "|  Epoch 35: Train loss: 0.422 (BinaryAccuracy: 0.812, BinaryAUROC: 0.813)  Valid loss: 0.326 (BinaryAccuracy: 0.901, BinaryAUROC: 0.899)\n",
      "|  Epoch 36: Train loss: 0.42 (BinaryAccuracy: 0.809, BinaryAUROC: 0.812)  Valid loss: 0.355 (BinaryAccuracy: 0.859, BinaryAUROC: 0.857)\n",
      "|  Epoch 37: Train loss: 0.46 (BinaryAccuracy: 0.793, BinaryAUROC: 0.792)  Valid loss: 0.332 (BinaryAccuracy: 0.911, BinaryAUROC: 0.909)\n",
      "*  Epoch 38: Train loss: 0.433 (BinaryAccuracy: 0.789, BinaryAUROC: 0.79)  Valid loss: 0.313 (BinaryAccuracy: 0.901, BinaryAUROC: 0.899)\n",
      "*  Epoch 39: Train loss: 0.415 (BinaryAccuracy: 0.812, BinaryAUROC: 0.812)  Valid loss: 0.31 (BinaryAccuracy: 0.891, BinaryAUROC: 0.889)\n",
      "*  Epoch 40: Train loss: 0.4 (BinaryAccuracy: 0.817, BinaryAUROC: 0.816)  Valid loss: 0.297 (BinaryAccuracy: 0.896, BinaryAUROC: 0.895)\n",
      "|  Epoch 41: Train loss: 0.377 (BinaryAccuracy: 0.831, BinaryAUROC: 0.833)  Valid loss: 0.321 (BinaryAccuracy: 0.87, BinaryAUROC: 0.87)\n",
      "|  Epoch 42: Train loss: 0.383 (BinaryAccuracy: 0.819, BinaryAUROC: 0.819)  Valid loss: 0.319 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 43: Train loss: 0.389 (BinaryAccuracy: 0.822, BinaryAUROC: 0.822)  Valid loss: 0.325 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 44: Train loss: 0.349 (BinaryAccuracy: 0.853, BinaryAUROC: 0.853)  Valid loss: 0.298 (BinaryAccuracy: 0.901, BinaryAUROC: 0.9)\n",
      "|  Epoch 45: Train loss: 0.393 (BinaryAccuracy: 0.829, BinaryAUROC: 0.831)  Valid loss: 0.317 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 46: Train loss: 0.371 (BinaryAccuracy: 0.84, BinaryAUROC: 0.841)  Valid loss: 0.302 (BinaryAccuracy: 0.896, BinaryAUROC: 0.893)\n",
      "|  Epoch 47: Train loss: 0.403 (BinaryAccuracy: 0.821, BinaryAUROC: 0.821)  Valid loss: 0.331 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 48: Train loss: 0.395 (BinaryAccuracy: 0.821, BinaryAUROC: 0.82)  Valid loss: 0.298 (BinaryAccuracy: 0.901, BinaryAUROC: 0.899)\n",
      "|  Epoch 49: Train loss: 0.4 (BinaryAccuracy: 0.826, BinaryAUROC: 0.826)  Valid loss: 0.331 (BinaryAccuracy: 0.906, BinaryAUROC: 0.905)\n",
      "|  Epoch 50: Train loss: 0.371 (BinaryAccuracy: 0.835, BinaryAUROC: 0.835)  Valid loss: 0.316 (BinaryAccuracy: 0.896, BinaryAUROC: 0.892)\n",
      "|  Epoch 51: Train loss: 0.344 (BinaryAccuracy: 0.844, BinaryAUROC: 0.844)  Valid loss: 0.316 (BinaryAccuracy: 0.87, BinaryAUROC: 0.869)\n",
      "|  Epoch 52: Train loss: 0.386 (BinaryAccuracy: 0.834, BinaryAUROC: 0.834)  Valid loss: 0.36 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "*  Epoch 53: Train loss: 0.362 (BinaryAccuracy: 0.827, BinaryAUROC: 0.827)  Valid loss: 0.282 (BinaryAccuracy: 0.917, BinaryAUROC: 0.915)\n",
      "|  Epoch 54: Train loss: 0.355 (BinaryAccuracy: 0.846, BinaryAUROC: 0.847)  Valid loss: 0.298 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 55: Train loss: 0.356 (BinaryAccuracy: 0.829, BinaryAUROC: 0.829)  Valid loss: 0.297 (BinaryAccuracy: 0.891, BinaryAUROC: 0.89)\n",
      "|  Epoch 56: Train loss: 0.359 (BinaryAccuracy: 0.838, BinaryAUROC: 0.838)  Valid loss: 0.322 (BinaryAccuracy: 0.891, BinaryAUROC: 0.889)\n",
      "|  Epoch 57: Train loss: 0.359 (BinaryAccuracy: 0.849, BinaryAUROC: 0.849)  Valid loss: 0.325 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 58: Train loss: 0.37 (BinaryAccuracy: 0.832, BinaryAUROC: 0.833)  Valid loss: 0.325 (BinaryAccuracy: 0.865, BinaryAUROC: 0.865)\n",
      "|  Epoch 59: Train loss: 0.382 (BinaryAccuracy: 0.837, BinaryAUROC: 0.836)  Valid loss: 0.294 (BinaryAccuracy: 0.906, BinaryAUROC: 0.904)\n",
      "|  Epoch 60: Train loss: 0.37 (BinaryAccuracy: 0.834, BinaryAUROC: 0.834)  Valid loss: 0.335 (BinaryAccuracy: 0.906, BinaryAUROC: 0.905)\n",
      "|  Epoch 61: Train loss: 0.362 (BinaryAccuracy: 0.84, BinaryAUROC: 0.84)  Valid loss: 0.301 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 62: Train loss: 0.327 (BinaryAccuracy: 0.861, BinaryAUROC: 0.862)  Valid loss: 0.324 (BinaryAccuracy: 0.849, BinaryAUROC: 0.85)\n",
      "|  Epoch 63: Train loss: 0.334 (BinaryAccuracy: 0.853, BinaryAUROC: 0.853)  Valid loss: 0.312 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 64: Train loss: 0.365 (BinaryAccuracy: 0.837, BinaryAUROC: 0.837)  Valid loss: 0.32 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 65: Train loss: 0.349 (BinaryAccuracy: 0.849, BinaryAUROC: 0.85)  Valid loss: 0.322 (BinaryAccuracy: 0.875, BinaryAUROC: 0.871)\n",
      "|  Epoch 66: Train loss: 0.35 (BinaryAccuracy: 0.844, BinaryAUROC: 0.844)  Valid loss: 0.336 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)\n",
      "|  Epoch 67: Train loss: 0.326 (BinaryAccuracy: 0.859, BinaryAUROC: 0.861)  Valid loss: 0.347 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 68: Train loss: 0.353 (BinaryAccuracy: 0.847, BinaryAUROC: 0.847)  Valid loss: 0.351 (BinaryAccuracy: 0.844, BinaryAUROC: 0.843)\n",
      "|  Epoch 69: Train loss: 0.34 (BinaryAccuracy: 0.858, BinaryAUROC: 0.857)  Valid loss: 0.311 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 70: Train loss: 0.332 (BinaryAccuracy: 0.856, BinaryAUROC: 0.857)  Valid loss: 0.29 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 71: Train loss: 0.317 (BinaryAccuracy: 0.861, BinaryAUROC: 0.861)  Valid loss: 0.333 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 72: Train loss: 0.34 (BinaryAccuracy: 0.853, BinaryAUROC: 0.853)  Valid loss: 0.335 (BinaryAccuracy: 0.859, BinaryAUROC: 0.857)\n",
      "|  Epoch 73: Train loss: 0.322 (BinaryAccuracy: 0.855, BinaryAUROC: 0.855)  Valid loss: 0.334 (BinaryAccuracy: 0.859, BinaryAUROC: 0.857)\n",
      "*  Epoch 74: Train loss: 0.361 (BinaryAccuracy: 0.845, BinaryAUROC: 0.846)  Valid loss: 0.28 (BinaryAccuracy: 0.896, BinaryAUROC: 0.895)\n",
      "|  Epoch 75: Train loss: 0.331 (BinaryAccuracy: 0.846, BinaryAUROC: 0.846)  Valid loss: 0.316 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 76: Train loss: 0.35 (BinaryAccuracy: 0.848, BinaryAUROC: 0.847)  Valid loss: 0.339 (BinaryAccuracy: 0.859, BinaryAUROC: 0.857)\n",
      "|  Epoch 77: Train loss: 0.34 (BinaryAccuracy: 0.85, BinaryAUROC: 0.85)  Valid loss: 0.344 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "|  Epoch 78: Train loss: 0.305 (BinaryAccuracy: 0.877, BinaryAUROC: 0.878)  Valid loss: 0.31 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 79: Train loss: 0.339 (BinaryAccuracy: 0.849, BinaryAUROC: 0.849)  Valid loss: 0.32 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 80: Train loss: 0.327 (BinaryAccuracy: 0.858, BinaryAUROC: 0.859)  Valid loss: 0.329 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 81: Train loss: 0.347 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)  Valid loss: 0.285 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 82: Train loss: 0.332 (BinaryAccuracy: 0.856, BinaryAUROC: 0.856)  Valid loss: 0.321 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 83: Train loss: 0.317 (BinaryAccuracy: 0.858, BinaryAUROC: 0.859)  Valid loss: 0.328 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 84: Train loss: 0.317 (BinaryAccuracy: 0.864, BinaryAUROC: 0.864)  Valid loss: 0.327 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 85: Train loss: 0.335 (BinaryAccuracy: 0.854, BinaryAUROC: 0.855)  Valid loss: 0.314 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 86: Train loss: 0.352 (BinaryAccuracy: 0.846, BinaryAUROC: 0.846)  Valid loss: 0.312 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 87: Train loss: 0.333 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)  Valid loss: 0.32 (BinaryAccuracy: 0.885, BinaryAUROC: 0.885)\n",
      "|  Epoch 88: Train loss: 0.34 (BinaryAccuracy: 0.854, BinaryAUROC: 0.855)  Valid loss: 0.307 (BinaryAccuracy: 0.901, BinaryAUROC: 0.9)\n",
      "|  Epoch 89: Train loss: 0.315 (BinaryAccuracy: 0.868, BinaryAUROC: 0.867)  Valid loss: 0.296 (BinaryAccuracy: 0.906, BinaryAUROC: 0.905)\n",
      "|  Epoch 90: Train loss: 0.304 (BinaryAccuracy: 0.873, BinaryAUROC: 0.873)  Valid loss: 0.319 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)\n",
      "|  Epoch 91: Train loss: 0.342 (BinaryAccuracy: 0.855, BinaryAUROC: 0.855)  Valid loss: 0.305 (BinaryAccuracy: 0.891, BinaryAUROC: 0.888)\n",
      "|  Epoch 92: Train loss: 0.344 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)  Valid loss: 0.296 (BinaryAccuracy: 0.906, BinaryAUROC: 0.905)\n",
      "|  Epoch 93: Train loss: 0.328 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)  Valid loss: 0.305 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 94: Train loss: 0.324 (BinaryAccuracy: 0.852, BinaryAUROC: 0.851)  Valid loss: 0.297 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 95: Train loss: 0.322 (BinaryAccuracy: 0.866, BinaryAUROC: 0.866)  Valid loss: 0.311 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 96: Train loss: 0.297 (BinaryAccuracy: 0.876, BinaryAUROC: 0.876)  Valid loss: 0.333 (BinaryAccuracy: 0.865, BinaryAUROC: 0.862)\n",
      "|  Epoch 97: Train loss: 0.306 (BinaryAccuracy: 0.869, BinaryAUROC: 0.87)  Valid loss: 0.291 (BinaryAccuracy: 0.901, BinaryAUROC: 0.9)\n",
      "|  Epoch 98: Train loss: 0.332 (BinaryAccuracy: 0.853, BinaryAUROC: 0.854)  Valid loss: 0.303 (BinaryAccuracy: 0.901, BinaryAUROC: 0.898)\n",
      "|  Epoch 99: Train loss: 0.307 (BinaryAccuracy: 0.871, BinaryAUROC: 0.871)  Valid loss: 0.308 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 100: Train loss: 0.319 (BinaryAccuracy: 0.862, BinaryAUROC: 0.862)  Valid loss: 0.313 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 101: Train loss: 0.319 (BinaryAccuracy: 0.858, BinaryAUROC: 0.858)  Valid loss: 0.305 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 102: Train loss: 0.334 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.306 (BinaryAccuracy: 0.885, BinaryAUROC: 0.883)\n",
      "|  Epoch 103: Train loss: 0.305 (BinaryAccuracy: 0.866, BinaryAUROC: 0.867)  Valid loss: 0.301 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 104: Train loss: 0.303 (BinaryAccuracy: 0.883, BinaryAUROC: 0.884)  Valid loss: 0.321 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 105: Train loss: 0.32 (BinaryAccuracy: 0.862, BinaryAUROC: 0.864)  Valid loss: 0.326 (BinaryAccuracy: 0.854, BinaryAUROC: 0.852)\n",
      "|  Epoch 106: Train loss: 0.322 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.323 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "|  Epoch 107: Train loss: 0.319 (BinaryAccuracy: 0.856, BinaryAUROC: 0.857)  Valid loss: 0.294 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 108: Train loss: 0.308 (BinaryAccuracy: 0.864, BinaryAUROC: 0.864)  Valid loss: 0.319 (BinaryAccuracy: 0.896, BinaryAUROC: 0.893)\n",
      "|  Epoch 109: Train loss: 0.326 (BinaryAccuracy: 0.851, BinaryAUROC: 0.852)  Valid loss: 0.282 (BinaryAccuracy: 0.891, BinaryAUROC: 0.889)\n",
      "|  Epoch 110: Train loss: 0.322 (BinaryAccuracy: 0.863, BinaryAUROC: 0.864)  Valid loss: 0.324 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "|  Epoch 111: Train loss: 0.325 (BinaryAccuracy: 0.863, BinaryAUROC: 0.862)  Valid loss: 0.298 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 112: Train loss: 0.304 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)  Valid loss: 0.303 (BinaryAccuracy: 0.865, BinaryAUROC: 0.866)\n",
      "|  Epoch 113: Train loss: 0.301 (BinaryAccuracy: 0.879, BinaryAUROC: 0.879)  Valid loss: 0.319 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "*  Epoch 114: Train loss: 0.312 (BinaryAccuracy: 0.864, BinaryAUROC: 0.864)  Valid loss: 0.279 (BinaryAccuracy: 0.891, BinaryAUROC: 0.889)\n",
      "|  Epoch 115: Train loss: 0.318 (BinaryAccuracy: 0.871, BinaryAUROC: 0.871)  Valid loss: 0.308 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)\n",
      "|  Epoch 116: Train loss: 0.297 (BinaryAccuracy: 0.874, BinaryAUROC: 0.874)  Valid loss: 0.303 (BinaryAccuracy: 0.891, BinaryAUROC: 0.888)\n",
      "|  Epoch 117: Train loss: 0.308 (BinaryAccuracy: 0.863, BinaryAUROC: 0.864)  Valid loss: 0.319 (BinaryAccuracy: 0.891, BinaryAUROC: 0.89)\n",
      "|  Epoch 118: Train loss: 0.276 (BinaryAccuracy: 0.891, BinaryAUROC: 0.891)  Valid loss: 0.294 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 119: Train loss: 0.302 (BinaryAccuracy: 0.882, BinaryAUROC: 0.882)  Valid loss: 0.324 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 120: Train loss: 0.327 (BinaryAccuracy: 0.868, BinaryAUROC: 0.867)  Valid loss: 0.285 (BinaryAccuracy: 0.891, BinaryAUROC: 0.89)\n",
      "|  Epoch 121: Train loss: 0.326 (BinaryAccuracy: 0.857, BinaryAUROC: 0.857)  Valid loss: 0.32 (BinaryAccuracy: 0.87, BinaryAUROC: 0.867)\n",
      "|  Epoch 122: Train loss: 0.287 (BinaryAccuracy: 0.88, BinaryAUROC: 0.88)  Valid loss: 0.317 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "|  Epoch 123: Train loss: 0.315 (BinaryAccuracy: 0.866, BinaryAUROC: 0.866)  Valid loss: 0.319 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "|  Epoch 124: Train loss: 0.31 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)  Valid loss: 0.306 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 125: Train loss: 0.313 (BinaryAccuracy: 0.863, BinaryAUROC: 0.862)  Valid loss: 0.309 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 126: Train loss: 0.324 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.314 (BinaryAccuracy: 0.865, BinaryAUROC: 0.862)\n",
      "|  Epoch 127: Train loss: 0.305 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)  Valid loss: 0.309 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "*  Epoch 128: Train loss: 0.333 (BinaryAccuracy: 0.865, BinaryAUROC: 0.865)  Valid loss: 0.279 (BinaryAccuracy: 0.891, BinaryAUROC: 0.891)\n",
      "|  Epoch 129: Train loss: 0.341 (BinaryAccuracy: 0.858, BinaryAUROC: 0.858)  Valid loss: 0.294 (BinaryAccuracy: 0.885, BinaryAUROC: 0.883)\n",
      "|  Epoch 130: Train loss: 0.304 (BinaryAccuracy: 0.876, BinaryAUROC: 0.876)  Valid loss: 0.298 (BinaryAccuracy: 0.865, BinaryAUROC: 0.864)\n",
      "|  Epoch 131: Train loss: 0.317 (BinaryAccuracy: 0.872, BinaryAUROC: 0.873)  Valid loss: 0.31 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 132: Train loss: 0.322 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.289 (BinaryAccuracy: 0.891, BinaryAUROC: 0.888)\n",
      "|  Epoch 133: Train loss: 0.311 (BinaryAccuracy: 0.876, BinaryAUROC: 0.876)  Valid loss: 0.314 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 134: Train loss: 0.317 (BinaryAccuracy: 0.868, BinaryAUROC: 0.867)  Valid loss: 0.299 (BinaryAccuracy: 0.875, BinaryAUROC: 0.874)\n",
      "|  Epoch 135: Train loss: 0.331 (BinaryAccuracy: 0.86, BinaryAUROC: 0.86)  Valid loss: 0.305 (BinaryAccuracy: 0.865, BinaryAUROC: 0.864)\n",
      "|  Epoch 136: Train loss: 0.301 (BinaryAccuracy: 0.879, BinaryAUROC: 0.879)  Valid loss: 0.299 (BinaryAccuracy: 0.901, BinaryAUROC: 0.898)\n",
      "|  Epoch 137: Train loss: 0.314 (BinaryAccuracy: 0.876, BinaryAUROC: 0.876)  Valid loss: 0.33 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "|  Epoch 138: Train loss: 0.32 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)  Valid loss: 0.306 (BinaryAccuracy: 0.859, BinaryAUROC: 0.86)\n",
      "|  Epoch 139: Train loss: 0.316 (BinaryAccuracy: 0.868, BinaryAUROC: 0.868)  Valid loss: 0.312 (BinaryAccuracy: 0.865, BinaryAUROC: 0.864)\n",
      "|  Epoch 140: Train loss: 0.337 (BinaryAccuracy: 0.852, BinaryAUROC: 0.853)  Valid loss: 0.32 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 141: Train loss: 0.314 (BinaryAccuracy: 0.859, BinaryAUROC: 0.86)  Valid loss: 0.313 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 142: Train loss: 0.318 (BinaryAccuracy: 0.869, BinaryAUROC: 0.87)  Valid loss: 0.326 (BinaryAccuracy: 0.865, BinaryAUROC: 0.864)\n",
      "*  Epoch 143: Train loss: 0.317 (BinaryAccuracy: 0.858, BinaryAUROC: 0.858)  Valid loss: 0.277 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 144: Train loss: 0.298 (BinaryAccuracy: 0.871, BinaryAUROC: 0.871)  Valid loss: 0.313 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 145: Train loss: 0.31 (BinaryAccuracy: 0.878, BinaryAUROC: 0.878)  Valid loss: 0.3 (BinaryAccuracy: 0.891, BinaryAUROC: 0.889)\n",
      "|  Epoch 146: Train loss: 0.283 (BinaryAccuracy: 0.893, BinaryAUROC: 0.894)  Valid loss: 0.324 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "|  Epoch 147: Train loss: 0.311 (BinaryAccuracy: 0.873, BinaryAUROC: 0.872)  Valid loss: 0.316 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 148: Train loss: 0.315 (BinaryAccuracy: 0.863, BinaryAUROC: 0.862)  Valid loss: 0.327 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 149: Train loss: 0.308 (BinaryAccuracy: 0.873, BinaryAUROC: 0.873)  Valid loss: 0.318 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 150: Train loss: 0.328 (BinaryAccuracy: 0.866, BinaryAUROC: 0.866)  Valid loss: 0.307 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 151: Train loss: 0.297 (BinaryAccuracy: 0.886, BinaryAUROC: 0.885)  Valid loss: 0.309 (BinaryAccuracy: 0.854, BinaryAUROC: 0.856)\n",
      "|  Epoch 152: Train loss: 0.312 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.314 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 153: Train loss: 0.321 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.313 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 154: Train loss: 0.292 (BinaryAccuracy: 0.882, BinaryAUROC: 0.882)  Valid loss: 0.328 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 155: Train loss: 0.314 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.293 (BinaryAccuracy: 0.901, BinaryAUROC: 0.899)\n",
      "|  Epoch 156: Train loss: 0.291 (BinaryAccuracy: 0.876, BinaryAUROC: 0.877)  Valid loss: 0.288 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 157: Train loss: 0.318 (BinaryAccuracy: 0.868, BinaryAUROC: 0.868)  Valid loss: 0.318 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 158: Train loss: 0.312 (BinaryAccuracy: 0.87, BinaryAUROC: 0.87)  Valid loss: 0.323 (BinaryAccuracy: 0.844, BinaryAUROC: 0.843)\n",
      "|  Epoch 159: Train loss: 0.308 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.322 (BinaryAccuracy: 0.87, BinaryAUROC: 0.867)\n",
      "|  Epoch 160: Train loss: 0.311 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.311 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 161: Train loss: 0.305 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.278 (BinaryAccuracy: 0.896, BinaryAUROC: 0.894)\n",
      "|  Epoch 162: Train loss: 0.311 (BinaryAccuracy: 0.868, BinaryAUROC: 0.868)  Valid loss: 0.324 (BinaryAccuracy: 0.87, BinaryAUROC: 0.869)\n",
      "|  Epoch 163: Train loss: 0.307 (BinaryAccuracy: 0.877, BinaryAUROC: 0.877)  Valid loss: 0.311 (BinaryAccuracy: 0.87, BinaryAUROC: 0.867)\n",
      "|  Epoch 164: Train loss: 0.326 (BinaryAccuracy: 0.864, BinaryAUROC: 0.864)  Valid loss: 0.295 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 165: Train loss: 0.297 (BinaryAccuracy: 0.876, BinaryAUROC: 0.876)  Valid loss: 0.307 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 166: Train loss: 0.303 (BinaryAccuracy: 0.877, BinaryAUROC: 0.878)  Valid loss: 0.311 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 167: Train loss: 0.318 (BinaryAccuracy: 0.865, BinaryAUROC: 0.865)  Valid loss: 0.316 (BinaryAccuracy: 0.854, BinaryAUROC: 0.855)\n",
      "|  Epoch 168: Train loss: 0.306 (BinaryAccuracy: 0.866, BinaryAUROC: 0.866)  Valid loss: 0.306 (BinaryAccuracy: 0.865, BinaryAUROC: 0.862)\n",
      "|  Epoch 169: Train loss: 0.336 (BinaryAccuracy: 0.855, BinaryAUROC: 0.856)  Valid loss: 0.311 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 170: Train loss: 0.306 (BinaryAccuracy: 0.873, BinaryAUROC: 0.873)  Valid loss: 0.315 (BinaryAccuracy: 0.87, BinaryAUROC: 0.869)\n",
      "|  Epoch 171: Train loss: 0.314 (BinaryAccuracy: 0.862, BinaryAUROC: 0.862)  Valid loss: 0.298 (BinaryAccuracy: 0.896, BinaryAUROC: 0.895)\n",
      "|  Epoch 172: Train loss: 0.306 (BinaryAccuracy: 0.868, BinaryAUROC: 0.867)  Valid loss: 0.31 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)\n",
      "|  Epoch 173: Train loss: 0.311 (BinaryAccuracy: 0.869, BinaryAUROC: 0.869)  Valid loss: 0.299 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "|  Epoch 174: Train loss: 0.29 (BinaryAccuracy: 0.878, BinaryAUROC: 0.878)  Valid loss: 0.301 (BinaryAccuracy: 0.88, BinaryAUROC: 0.879)\n",
      "|  Epoch 175: Train loss: 0.314 (BinaryAccuracy: 0.868, BinaryAUROC: 0.868)  Valid loss: 0.309 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 176: Train loss: 0.307 (BinaryAccuracy: 0.87, BinaryAUROC: 0.87)  Valid loss: 0.312 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)\n",
      "|  Epoch 177: Train loss: 0.321 (BinaryAccuracy: 0.861, BinaryAUROC: 0.862)  Valid loss: 0.29 (BinaryAccuracy: 0.885, BinaryAUROC: 0.886)\n",
      "|  Epoch 178: Train loss: 0.297 (BinaryAccuracy: 0.873, BinaryAUROC: 0.873)  Valid loss: 0.309 (BinaryAccuracy: 0.87, BinaryAUROC: 0.868)\n",
      "|  Epoch 179: Train loss: 0.308 (BinaryAccuracy: 0.869, BinaryAUROC: 0.87)  Valid loss: 0.308 (BinaryAccuracy: 0.911, BinaryAUROC: 0.909)\n",
      "|  Epoch 180: Train loss: 0.317 (BinaryAccuracy: 0.86, BinaryAUROC: 0.861)  Valid loss: 0.294 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 181: Train loss: 0.323 (BinaryAccuracy: 0.865, BinaryAUROC: 0.865)  Valid loss: 0.296 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 182: Train loss: 0.299 (BinaryAccuracy: 0.879, BinaryAUROC: 0.879)  Valid loss: 0.302 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 183: Train loss: 0.309 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.306 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 184: Train loss: 0.291 (BinaryAccuracy: 0.886, BinaryAUROC: 0.886)  Valid loss: 0.283 (BinaryAccuracy: 0.88, BinaryAUROC: 0.883)\n",
      "|  Epoch 185: Train loss: 0.311 (BinaryAccuracy: 0.867, BinaryAUROC: 0.868)  Valid loss: 0.334 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 186: Train loss: 0.291 (BinaryAccuracy: 0.878, BinaryAUROC: 0.879)  Valid loss: 0.317 (BinaryAccuracy: 0.854, BinaryAUROC: 0.853)\n",
      "|  Epoch 187: Train loss: 0.31 (BinaryAccuracy: 0.872, BinaryAUROC: 0.872)  Valid loss: 0.282 (BinaryAccuracy: 0.896, BinaryAUROC: 0.893)\n",
      "|  Epoch 188: Train loss: 0.325 (BinaryAccuracy: 0.863, BinaryAUROC: 0.863)  Valid loss: 0.312 (BinaryAccuracy: 0.849, BinaryAUROC: 0.848)\n",
      "|  Epoch 189: Train loss: 0.306 (BinaryAccuracy: 0.866, BinaryAUROC: 0.866)  Valid loss: 0.313 (BinaryAccuracy: 0.844, BinaryAUROC: 0.845)\n",
      "|  Epoch 190: Train loss: 0.304 (BinaryAccuracy: 0.865, BinaryAUROC: 0.866)  Valid loss: 0.306 (BinaryAccuracy: 0.885, BinaryAUROC: 0.884)\n",
      "|  Epoch 191: Train loss: 0.296 (BinaryAccuracy: 0.868, BinaryAUROC: 0.869)  Valid loss: 0.309 (BinaryAccuracy: 0.865, BinaryAUROC: 0.863)\n",
      "|  Epoch 192: Train loss: 0.302 (BinaryAccuracy: 0.874, BinaryAUROC: 0.875)  Valid loss: 0.314 (BinaryAccuracy: 0.839, BinaryAUROC: 0.838)\n",
      "|  Epoch 193: Train loss: 0.334 (BinaryAccuracy: 0.856, BinaryAUROC: 0.856)  Valid loss: 0.312 (BinaryAccuracy: 0.865, BinaryAUROC: 0.864)\n",
      "|  Epoch 194: Train loss: 0.311 (BinaryAccuracy: 0.872, BinaryAUROC: 0.873)  Valid loss: 0.329 (BinaryAccuracy: 0.88, BinaryAUROC: 0.878)\n",
      "|  Epoch 195: Train loss: 0.315 (BinaryAccuracy: 0.864, BinaryAUROC: 0.864)  Valid loss: 0.304 (BinaryAccuracy: 0.885, BinaryAUROC: 0.883)\n",
      "|  Epoch 196: Train loss: 0.324 (BinaryAccuracy: 0.868, BinaryAUROC: 0.868)  Valid loss: 0.307 (BinaryAccuracy: 0.859, BinaryAUROC: 0.859)\n",
      "|  Epoch 197: Train loss: 0.311 (BinaryAccuracy: 0.879, BinaryAUROC: 0.879)  Valid loss: 0.31 (BinaryAccuracy: 0.875, BinaryAUROC: 0.875)\n",
      "|  Epoch 198: Train loss: 0.313 (BinaryAccuracy: 0.856, BinaryAUROC: 0.855)  Valid loss: 0.305 (BinaryAccuracy: 0.875, BinaryAUROC: 0.873)\n",
      "|  Epoch 199: Train loss: 0.33 (BinaryAccuracy: 0.852, BinaryAUROC: 0.852)  Valid loss: 0.322 (BinaryAccuracy: 0.859, BinaryAUROC: 0.858)\n",
      "|  Epoch 200: Train loss: 0.286 (BinaryAccuracy: 0.879, BinaryAUROC: 0.879)  Valid loss: 0.319 (BinaryAccuracy: 0.891, BinaryAUROC: 0.888)\n",
      "------------------------------------------------\n",
      "Using Epoch 143 for testing...\n",
      "Test loss: 0.788\n",
      "Test BinaryAccuracy: 0.688\n",
      "Test BinaryAUROC: 0.687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNSetRepClassifier(num_node_features, 256, 6, num_edge_features, 8, 16)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    scheduler=scheduler,\n",
    "    # monitor_metric=1,\n",
    "    # monitor_lower_is_better=False\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GNNClassifier' object has no attribute 'Wc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m      7\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[1;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     10\u001b[0m     model,\n\u001b[1;32m     11\u001b[0m     optimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# monitor_lower_is_better=False\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(train_loader, valid_loader)\n\u001b[1;32m     23\u001b[0m trainer\u001b[39m.\u001b[39mtest(test_loader)\n",
      "File \u001b[0;32m~/Code/molsetrep/src/molsetrep/utils/trainer.py:125\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m    121\u001b[0m monitored_value \u001b[39m=\u001b[39m monitored_metric\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    123\u001b[0m \u001b[39m# Build history of hidden sets\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_set_history\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 125\u001b[0m     (epoch, monitored_value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mWc\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    126\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[39m# Remember the best epoch\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmonitor_lower_is_better:\n",
      "File \u001b[0;32m~/miniconda3/envs/molsetrep/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GNNClassifier' object has no attribute 'Wc'"
     ]
    }
   ],
   "source": [
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNClassifier(num_node_features, 256, 6, num_edge_features)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    scheduler=scheduler,\n",
    "    # monitor_metric=1,\n",
    "    # monitor_lower_is_better=False\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = molnet_loader(\"lipo\")\n",
    "train_loader, valid_loader, test_loader = molnet_to_pyg(\n",
    "    train,\n",
    "    valid,\n",
    "    test,\n",
    "    label_type=torch.float,\n",
    "    # atom_attrs=[\n",
    "    #     \"atomic_num\",\n",
    "    #     \"charge\",\n",
    "    #     \"aromatic\",\n",
    "    #     \"is_in_ring\",\n",
    "    #     \"hydrogen_count\",\n",
    "    #     \"hybridization_sp\",\n",
    "    #     \"hybridization_sp2\",\n",
    "    #     \"hybridization_sp3\",\n",
    "    #     \"hybridization_sp3d\",\n",
    "    #     \"hybridization_sp3d2\",\n",
    "    #     \"chiral_type_chi_tetrahedral_cw\",\n",
    "    #     \"chiral_type_chi_tetrahedral_ccw\",\n",
    "    #     \"chiral_type_chi_other\",\n",
    "    #     \"chiral_type_chi_tetrahedral\",\n",
    "    #     \"chiral_type_chi_allene\",\n",
    "    #     \"chiral_type_chi_squareplanar\",\n",
    "    #     \"chiral_type_chi_trigonalbipyramidal\",\n",
    "    #     \"chiral_type_chi_octahedral\",\n",
    "    #     \"degree\",\n",
    "    #     \"radical_count\"\n",
    "    # ]\n",
    ")\n",
    "\n",
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNSetRepRegressor(num_node_features, 512, 2, num_edge_features, 8, 16)\n",
    "# model = GNNRegressor(num_node_features, 512, 2, num_edge_features)\n",
    "# model = GNNSetRepRegressor(num_node_features, 512, 2, num_edge_features, 8, 32, gnn=GAT(num_node_features, 512, 4, jk=\"cat\", heads=8))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "explainer = RegressionExplainer(model, valid_loader)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    # scheduler=scheduler,\n",
    "    monitor_metric=1,\n",
    "    # monitor_lower_is_better=False\n",
    "    # explainer=explainer\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader, average_n_epochs=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
