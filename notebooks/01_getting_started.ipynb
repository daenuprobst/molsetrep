{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torchmetrics.classification import Accuracy, AUROC\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError\n",
    "\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "from molsetrep.utils.trainer import Trainer\n",
    "from molsetrep.utils.datasets import molnet_loader\n",
    "from molsetrep.utils.converters import molnet_to_pyg\n",
    "from molsetrep.utils.root_mean_squared_error import RootMeanSquaredError\n",
    "from molsetrep.models import GNNSetRepClassifier, GNNSetRepRegressor, GNNSetRepClassifierSubstruct, GNNRegressor\n",
    "from molsetrep.explain import RegressionExplainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to https://github.com/wengong-jin/chemprop\n",
    "train, valid, test = molnet_loader(\"hiv\", reload=False)\n",
    "train_loader, valid_loader, test_loader = molnet_to_pyg(\n",
    "    train,\n",
    "    valid,\n",
    "    test,\n",
    "    label_type=torch.long,\n",
    "    imbalanced_sampler=True,\n",
    "    secfp=False,\n",
    "    index_graphs=False,\n",
    "    # atom_attrs=[\"atomic_num\", \"charge\", \"hydrogen_count\"],\n",
    "    # bond_attrs=[\"bond_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Epoch 1: Train loss: 0.257 (BinaryAccuracy: 0.919, BinaryAUROC: 0.497)  Valid loss: 0.119 (BinaryAccuracy: 0.98, BinaryAUROC: 0.5)\n",
      "|  Epoch 2: Train loss: 0.16 (BinaryAccuracy: 0.963, BinaryAUROC: 0.501)  Valid loss: 0.109 (BinaryAccuracy: 0.98, BinaryAUROC: 0.5)\n",
      "*  Epoch 3: Train loss: 0.15 (BinaryAccuracy: 0.962, BinaryAUROC: 0.504)  Valid loss: 0.097 (BinaryAccuracy: 0.98, BinaryAUROC: 0.506)\n",
      "*  Epoch 4: Train loss: 0.147 (BinaryAccuracy: 0.963, BinaryAUROC: 0.52)  Valid loss: 0.096 (BinaryAccuracy: 0.981, BinaryAUROC: 0.506)\n",
      "*  Epoch 5: Train loss: 0.146 (BinaryAccuracy: 0.963, BinaryAUROC: 0.515)  Valid loss: 0.096 (BinaryAccuracy: 0.981, BinaryAUROC: 0.537)\n",
      "|  Epoch 6: Train loss: 0.143 (BinaryAccuracy: 0.963, BinaryAUROC: 0.521)  Valid loss: 0.097 (BinaryAccuracy: 0.98, BinaryAUROC: 0.531)\n",
      "|  Epoch 7: Train loss: 0.141 (BinaryAccuracy: 0.963, BinaryAUROC: 0.532)  Valid loss: 0.098 (BinaryAccuracy: 0.981, BinaryAUROC: 0.519)\n",
      "|  Epoch 8: Train loss: 0.14 (BinaryAccuracy: 0.964, BinaryAUROC: 0.538)  Valid loss: 0.091 (BinaryAccuracy: 0.98, BinaryAUROC: 0.531)\n",
      "|  Epoch 9: Train loss: 0.138 (BinaryAccuracy: 0.964, BinaryAUROC: 0.546)  Valid loss: 0.093 (BinaryAccuracy: 0.981, BinaryAUROC: 0.531)\n",
      "*  Epoch 10: Train loss: 0.137 (BinaryAccuracy: 0.964, BinaryAUROC: 0.546)  Valid loss: 0.091 (BinaryAccuracy: 0.978, BinaryAUROC: 0.566)\n",
      "|  Epoch 11: Train loss: 0.134 (BinaryAccuracy: 0.965, BinaryAUROC: 0.557)  Valid loss: 0.091 (BinaryAccuracy: 0.98, BinaryAUROC: 0.536)\n",
      "*  Epoch 12: Train loss: 0.134 (BinaryAccuracy: 0.964, BinaryAUROC: 0.556)  Valid loss: 0.086 (BinaryAccuracy: 0.981, BinaryAUROC: 0.603)\n",
      "|  Epoch 13: Train loss: 0.132 (BinaryAccuracy: 0.965, BinaryAUROC: 0.565)  Valid loss: 0.091 (BinaryAccuracy: 0.981, BinaryAUROC: 0.531)\n",
      "|  Epoch 14: Train loss: 0.132 (BinaryAccuracy: 0.965, BinaryAUROC: 0.566)  Valid loss: 0.085 (BinaryAccuracy: 0.981, BinaryAUROC: 0.531)\n",
      "|  Epoch 15: Train loss: 0.131 (BinaryAccuracy: 0.965, BinaryAUROC: 0.562)  Valid loss: 0.088 (BinaryAccuracy: 0.981, BinaryAUROC: 0.573)\n",
      "|  Epoch 16: Train loss: 0.129 (BinaryAccuracy: 0.965, BinaryAUROC: 0.571)  Valid loss: 0.089 (BinaryAccuracy: 0.981, BinaryAUROC: 0.555)\n",
      "|  Epoch 17: Train loss: 0.128 (BinaryAccuracy: 0.965, BinaryAUROC: 0.572)  Valid loss: 0.085 (BinaryAccuracy: 0.981, BinaryAUROC: 0.567)\n",
      "|  Epoch 18: Train loss: 0.126 (BinaryAccuracy: 0.967, BinaryAUROC: 0.586)  Valid loss: 0.087 (BinaryAccuracy: 0.982, BinaryAUROC: 0.543)\n",
      "|  Epoch 19: Train loss: 0.125 (BinaryAccuracy: 0.966, BinaryAUROC: 0.575)  Valid loss: 0.08 (BinaryAccuracy: 0.981, BinaryAUROC: 0.58)\n",
      "|  Epoch 20: Train loss: 0.125 (BinaryAccuracy: 0.967, BinaryAUROC: 0.589)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.567)\n",
      "|  Epoch 21: Train loss: 0.124 (BinaryAccuracy: 0.966, BinaryAUROC: 0.591)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.555)\n",
      "|  Epoch 22: Train loss: 0.123 (BinaryAccuracy: 0.966, BinaryAUROC: 0.588)  Valid loss: 0.077 (BinaryAccuracy: 0.982, BinaryAUROC: 0.598)\n",
      "|  Epoch 23: Train loss: 0.123 (BinaryAccuracy: 0.967, BinaryAUROC: 0.598)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.569)\n",
      "|  Epoch 24: Train loss: 0.121 (BinaryAccuracy: 0.967, BinaryAUROC: 0.596)  Valid loss: 0.083 (BinaryAccuracy: 0.981, BinaryAUROC: 0.597)\n",
      "|  Epoch 25: Train loss: 0.12 (BinaryAccuracy: 0.968, BinaryAUROC: 0.608)  Valid loss: 0.082 (BinaryAccuracy: 0.981, BinaryAUROC: 0.585)\n",
      "|  Epoch 26: Train loss: 0.119 (BinaryAccuracy: 0.968, BinaryAUROC: 0.614)  Valid loss: 0.08 (BinaryAccuracy: 0.981, BinaryAUROC: 0.597)\n",
      "|  Epoch 27: Train loss: 0.118 (BinaryAccuracy: 0.968, BinaryAUROC: 0.615)  Valid loss: 0.08 (BinaryAccuracy: 0.981, BinaryAUROC: 0.567)\n",
      "*  Epoch 28: Train loss: 0.117 (BinaryAccuracy: 0.968, BinaryAUROC: 0.616)  Valid loss: 0.078 (BinaryAccuracy: 0.983, BinaryAUROC: 0.628)\n",
      "|  Epoch 29: Train loss: 0.117 (BinaryAccuracy: 0.968, BinaryAUROC: 0.617)  Valid loss: 0.078 (BinaryAccuracy: 0.983, BinaryAUROC: 0.592)\n",
      "|  Epoch 30: Train loss: 0.116 (BinaryAccuracy: 0.968, BinaryAUROC: 0.621)  Valid loss: 0.085 (BinaryAccuracy: 0.983, BinaryAUROC: 0.574)\n",
      "|  Epoch 31: Train loss: 0.116 (BinaryAccuracy: 0.968, BinaryAUROC: 0.62)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.628)\n",
      "|  Epoch 32: Train loss: 0.115 (BinaryAccuracy: 0.968, BinaryAUROC: 0.623)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.604)\n",
      "|  Epoch 33: Train loss: 0.114 (BinaryAccuracy: 0.968, BinaryAUROC: 0.619)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.587)\n",
      "|  Epoch 34: Train loss: 0.113 (BinaryAccuracy: 0.969, BinaryAUROC: 0.628)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.628)\n",
      "|  Epoch 35: Train loss: 0.114 (BinaryAccuracy: 0.969, BinaryAUROC: 0.63)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.579)\n",
      "|  Epoch 36: Train loss: 0.112 (BinaryAccuracy: 0.969, BinaryAUROC: 0.628)  Valid loss: 0.083 (BinaryAccuracy: 0.979, BinaryAUROC: 0.585)\n",
      "|  Epoch 37: Train loss: 0.111 (BinaryAccuracy: 0.969, BinaryAUROC: 0.633)  Valid loss: 0.081 (BinaryAccuracy: 0.983, BinaryAUROC: 0.604)\n",
      "|  Epoch 38: Train loss: 0.111 (BinaryAccuracy: 0.97, BinaryAUROC: 0.64)  Valid loss: 0.079 (BinaryAccuracy: 0.981, BinaryAUROC: 0.628)\n",
      "|  Epoch 39: Train loss: 0.11 (BinaryAccuracy: 0.969, BinaryAUROC: 0.636)  Valid loss: 0.08 (BinaryAccuracy: 0.98, BinaryAUROC: 0.603)\n",
      "*  Epoch 40: Train loss: 0.11 (BinaryAccuracy: 0.97, BinaryAUROC: 0.641)  Valid loss: 0.082 (BinaryAccuracy: 0.98, BinaryAUROC: 0.633)\n",
      "|  Epoch 41: Train loss: 0.109 (BinaryAccuracy: 0.969, BinaryAUROC: 0.643)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.604)\n",
      "|  Epoch 42: Train loss: 0.107 (BinaryAccuracy: 0.97, BinaryAUROC: 0.641)  Valid loss: 0.081 (BinaryAccuracy: 0.98, BinaryAUROC: 0.575)\n",
      "|  Epoch 43: Train loss: 0.108 (BinaryAccuracy: 0.969, BinaryAUROC: 0.643)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.586)\n",
      "|  Epoch 44: Train loss: 0.106 (BinaryAccuracy: 0.97, BinaryAUROC: 0.647)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.61)\n",
      "|  Epoch 45: Train loss: 0.106 (BinaryAccuracy: 0.97, BinaryAUROC: 0.659)  Valid loss: 0.08 (BinaryAccuracy: 0.982, BinaryAUROC: 0.604)\n",
      "|  Epoch 46: Train loss: 0.106 (BinaryAccuracy: 0.97, BinaryAUROC: 0.648)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.598)\n",
      "|  Epoch 47: Train loss: 0.105 (BinaryAccuracy: 0.97, BinaryAUROC: 0.649)  Valid loss: 0.074 (BinaryAccuracy: 0.983, BinaryAUROC: 0.622)\n",
      "|  Epoch 48: Train loss: 0.103 (BinaryAccuracy: 0.971, BinaryAUROC: 0.661)  Valid loss: 0.079 (BinaryAccuracy: 0.979, BinaryAUROC: 0.584)\n",
      "|  Epoch 49: Train loss: 0.104 (BinaryAccuracy: 0.97, BinaryAUROC: 0.653)  Valid loss: 0.082 (BinaryAccuracy: 0.979, BinaryAUROC: 0.598)\n",
      "|  Epoch 50: Train loss: 0.103 (BinaryAccuracy: 0.971, BinaryAUROC: 0.662)  Valid loss: 0.082 (BinaryAccuracy: 0.98, BinaryAUROC: 0.585)\n",
      "|  Epoch 51: Train loss: 0.104 (BinaryAccuracy: 0.97, BinaryAUROC: 0.656)  Valid loss: 0.079 (BinaryAccuracy: 0.981, BinaryAUROC: 0.591)\n",
      "|  Epoch 52: Train loss: 0.102 (BinaryAccuracy: 0.971, BinaryAUROC: 0.663)  Valid loss: 0.08 (BinaryAccuracy: 0.982, BinaryAUROC: 0.598)\n",
      "|  Epoch 53: Train loss: 0.101 (BinaryAccuracy: 0.971, BinaryAUROC: 0.665)  Valid loss: 0.081 (BinaryAccuracy: 0.979, BinaryAUROC: 0.614)\n",
      "*  Epoch 54: Train loss: 0.101 (BinaryAccuracy: 0.971, BinaryAUROC: 0.666)  Valid loss: 0.08 (BinaryAccuracy: 0.983, BinaryAUROC: 0.634)\n",
      "|  Epoch 55: Train loss: 0.102 (BinaryAccuracy: 0.97, BinaryAUROC: 0.662)  Valid loss: 0.08 (BinaryAccuracy: 0.981, BinaryAUROC: 0.621)\n",
      "|  Epoch 56: Train loss: 0.101 (BinaryAccuracy: 0.971, BinaryAUROC: 0.671)  Valid loss: 0.077 (BinaryAccuracy: 0.981, BinaryAUROC: 0.597)\n",
      "|  Epoch 57: Train loss: 0.1 (BinaryAccuracy: 0.971, BinaryAUROC: 0.67)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.585)\n",
      "|  Epoch 58: Train loss: 0.1 (BinaryAccuracy: 0.971, BinaryAUROC: 0.669)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.603)\n",
      "|  Epoch 59: Train loss: 0.098 (BinaryAccuracy: 0.971, BinaryAUROC: 0.671)  Valid loss: 0.081 (BinaryAccuracy: 0.98, BinaryAUROC: 0.597)\n",
      "|  Epoch 60: Train loss: 0.098 (BinaryAccuracy: 0.971, BinaryAUROC: 0.674)  Valid loss: 0.085 (BinaryAccuracy: 0.979, BinaryAUROC: 0.615)\n",
      "|  Epoch 61: Train loss: 0.098 (BinaryAccuracy: 0.971, BinaryAUROC: 0.679)  Valid loss: 0.078 (BinaryAccuracy: 0.981, BinaryAUROC: 0.617)\n",
      "|  Epoch 62: Train loss: 0.097 (BinaryAccuracy: 0.972, BinaryAUROC: 0.673)  Valid loss: 0.084 (BinaryAccuracy: 0.98, BinaryAUROC: 0.609)\n",
      "|  Epoch 63: Train loss: 0.097 (BinaryAccuracy: 0.971, BinaryAUROC: 0.676)  Valid loss: 0.077 (BinaryAccuracy: 0.983, BinaryAUROC: 0.607)\n",
      "|  Epoch 64: Train loss: 0.097 (BinaryAccuracy: 0.972, BinaryAUROC: 0.677)  Valid loss: 0.082 (BinaryAccuracy: 0.982, BinaryAUROC: 0.61)\n",
      "|  Epoch 65: Train loss: 0.096 (BinaryAccuracy: 0.972, BinaryAUROC: 0.686)  Valid loss: 0.08 (BinaryAccuracy: 0.981, BinaryAUROC: 0.615)\n",
      "|  Epoch 66: Train loss: 0.096 (BinaryAccuracy: 0.972, BinaryAUROC: 0.683)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.621)\n",
      "|  Epoch 67: Train loss: 0.095 (BinaryAccuracy: 0.973, BinaryAUROC: 0.688)  Valid loss: 0.089 (BinaryAccuracy: 0.979, BinaryAUROC: 0.621)\n",
      "|  Epoch 68: Train loss: 0.095 (BinaryAccuracy: 0.972, BinaryAUROC: 0.687)  Valid loss: 0.084 (BinaryAccuracy: 0.983, BinaryAUROC: 0.622)\n",
      "|  Epoch 69: Train loss: 0.094 (BinaryAccuracy: 0.973, BinaryAUROC: 0.691)  Valid loss: 0.079 (BinaryAccuracy: 0.982, BinaryAUROC: 0.616)\n",
      "|  Epoch 70: Train loss: 0.094 (BinaryAccuracy: 0.972, BinaryAUROC: 0.69)  Valid loss: 0.091 (BinaryAccuracy: 0.98, BinaryAUROC: 0.573)\n",
      "|  Epoch 71: Train loss: 0.093 (BinaryAccuracy: 0.973, BinaryAUROC: 0.69)  Valid loss: 0.077 (BinaryAccuracy: 0.982, BinaryAUROC: 0.611)\n",
      "|  Epoch 72: Train loss: 0.094 (BinaryAccuracy: 0.972, BinaryAUROC: 0.691)  Valid loss: 0.081 (BinaryAccuracy: 0.982, BinaryAUROC: 0.598)\n",
      "|  Epoch 73: Train loss: 0.092 (BinaryAccuracy: 0.973, BinaryAUROC: 0.695)  Valid loss: 0.076 (BinaryAccuracy: 0.981, BinaryAUROC: 0.603)\n",
      "|  Epoch 74: Train loss: 0.091 (BinaryAccuracy: 0.973, BinaryAUROC: 0.695)  Valid loss: 0.083 (BinaryAccuracy: 0.98, BinaryAUROC: 0.621)\n",
      "|  Epoch 75: Train loss: 0.091 (BinaryAccuracy: 0.974, BinaryAUROC: 0.701)  Valid loss: 0.084 (BinaryAccuracy: 0.981, BinaryAUROC: 0.598)\n",
      "|  Epoch 76: Train loss: 0.091 (BinaryAccuracy: 0.972, BinaryAUROC: 0.688)  Valid loss: 0.076 (BinaryAccuracy: 0.983, BinaryAUROC: 0.634)\n",
      "|  Epoch 77: Train loss: 0.09 (BinaryAccuracy: 0.973, BinaryAUROC: 0.698)  Valid loss: 0.085 (BinaryAccuracy: 0.981, BinaryAUROC: 0.603)\n",
      "|  Epoch 78: Train loss: 0.09 (BinaryAccuracy: 0.974, BinaryAUROC: 0.7)  Valid loss: 0.08 (BinaryAccuracy: 0.982, BinaryAUROC: 0.617)\n",
      "|  Epoch 79: Train loss: 0.09 (BinaryAccuracy: 0.974, BinaryAUROC: 0.706)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.621)\n",
      "|  Epoch 80: Train loss: 0.089 (BinaryAccuracy: 0.973, BinaryAUROC: 0.699)  Valid loss: 0.085 (BinaryAccuracy: 0.98, BinaryAUROC: 0.597)\n",
      "|  Epoch 81: Train loss: 0.088 (BinaryAccuracy: 0.973, BinaryAUROC: 0.697)  Valid loss: 0.086 (BinaryAccuracy: 0.981, BinaryAUROC: 0.592)\n",
      "|  Epoch 82: Train loss: 0.087 (BinaryAccuracy: 0.974, BinaryAUROC: 0.708)  Valid loss: 0.08 (BinaryAccuracy: 0.98, BinaryAUROC: 0.615)\n",
      "|  Epoch 83: Train loss: 0.087 (BinaryAccuracy: 0.974, BinaryAUROC: 0.71)  Valid loss: 0.089 (BinaryAccuracy: 0.979, BinaryAUROC: 0.608)\n",
      "*  Epoch 84: Train loss: 0.087 (BinaryAccuracy: 0.974, BinaryAUROC: 0.708)  Valid loss: 0.078 (BinaryAccuracy: 0.982, BinaryAUROC: 0.64)\n",
      "|  Epoch 85: Train loss: 0.086 (BinaryAccuracy: 0.974, BinaryAUROC: 0.712)  Valid loss: 0.083 (BinaryAccuracy: 0.978, BinaryAUROC: 0.597)\n",
      "|  Epoch 86: Train loss: 0.086 (BinaryAccuracy: 0.973, BinaryAUROC: 0.705)  Valid loss: 0.086 (BinaryAccuracy: 0.981, BinaryAUROC: 0.623)\n",
      "|  Epoch 87: Train loss: 0.086 (BinaryAccuracy: 0.974, BinaryAUROC: 0.71)  Valid loss: 0.083 (BinaryAccuracy: 0.979, BinaryAUROC: 0.615)\n",
      "|  Epoch 88: Train loss: 0.086 (BinaryAccuracy: 0.974, BinaryAUROC: 0.712)  Valid loss: 0.078 (BinaryAccuracy: 0.981, BinaryAUROC: 0.634)\n",
      "|  Epoch 89: Train loss: 0.085 (BinaryAccuracy: 0.974, BinaryAUROC: 0.714)  Valid loss: 0.082 (BinaryAccuracy: 0.98, BinaryAUROC: 0.585)\n",
      "|  Epoch 90: Train loss: 0.084 (BinaryAccuracy: 0.974, BinaryAUROC: 0.714)  Valid loss: 0.086 (BinaryAccuracy: 0.979, BinaryAUROC: 0.626)\n",
      "|  Epoch 91: Train loss: 0.084 (BinaryAccuracy: 0.973, BinaryAUROC: 0.714)  Valid loss: 0.086 (BinaryAccuracy: 0.982, BinaryAUROC: 0.586)\n",
      "|  Epoch 92: Train loss: 0.083 (BinaryAccuracy: 0.974, BinaryAUROC: 0.717)  Valid loss: 0.081 (BinaryAccuracy: 0.982, BinaryAUROC: 0.622)\n",
      "|  Epoch 93: Train loss: 0.083 (BinaryAccuracy: 0.974, BinaryAUROC: 0.718)  Valid loss: 0.083 (BinaryAccuracy: 0.979, BinaryAUROC: 0.596)\n",
      "|  Epoch 94: Train loss: 0.082 (BinaryAccuracy: 0.974, BinaryAUROC: 0.723)  Valid loss: 0.087 (BinaryAccuracy: 0.981, BinaryAUROC: 0.579)\n",
      "|  Epoch 95: Train loss: 0.082 (BinaryAccuracy: 0.975, BinaryAUROC: 0.721)  Valid loss: 0.081 (BinaryAccuracy: 0.981, BinaryAUROC: 0.609)\n",
      "|  Epoch 96: Train loss: 0.081 (BinaryAccuracy: 0.975, BinaryAUROC: 0.724)  Valid loss: 0.089 (BinaryAccuracy: 0.979, BinaryAUROC: 0.602)\n",
      "|  Epoch 97: Train loss: 0.081 (BinaryAccuracy: 0.975, BinaryAUROC: 0.724)  Valid loss: 0.087 (BinaryAccuracy: 0.981, BinaryAUROC: 0.593)\n",
      "|  Epoch 98: Train loss: 0.081 (BinaryAccuracy: 0.974, BinaryAUROC: 0.719)  Valid loss: 0.085 (BinaryAccuracy: 0.98, BinaryAUROC: 0.573)\n",
      "|  Epoch 99: Train loss: 0.078 (BinaryAccuracy: 0.976, BinaryAUROC: 0.733)  Valid loss: 0.082 (BinaryAccuracy: 0.981, BinaryAUROC: 0.604)\n",
      "|  Epoch 100: Train loss: 0.08 (BinaryAccuracy: 0.975, BinaryAUROC: 0.73)  Valid loss: 0.087 (BinaryAccuracy: 0.979, BinaryAUROC: 0.621)\n",
      "------------------------------------------------\n",
      "Using Epoch 84 for testing...\n",
      "Test loss: 0.145\n",
      "Test BinaryAccuracy: 0.966\n",
      "Test BinaryAUROC: 0.574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNSetRepClassifier(num_node_features, 256, 2, num_edge_features, 16, 32)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    100,\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    [Accuracy(task=\"binary\"), AUROC(task=\"binary\")],\n",
    "    # scheduler=scheduler,\n",
    "    monitor_metric=1,\n",
    "    monitor_lower_is_better=False\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = molnet_loader(\"lipo\")\n",
    "train_loader, valid_loader, test_loader = molnet_to_pyg(\n",
    "    train,\n",
    "    valid,\n",
    "    test,\n",
    "    label_type=torch.float,\n",
    "    # atom_attrs=[\n",
    "    #     \"atomic_num\",\n",
    "    #     \"charge\",\n",
    "    #     \"aromatic\",\n",
    "    #     \"is_in_ring\",\n",
    "    #     \"hydrogen_count\",\n",
    "    #     \"hybridization_sp\",\n",
    "    #     \"hybridization_sp2\",\n",
    "    #     \"hybridization_sp3\",\n",
    "    #     \"hybridization_sp3d\",\n",
    "    #     \"hybridization_sp3d2\",\n",
    "    #     \"chiral_type_chi_tetrahedral_cw\",\n",
    "    #     \"chiral_type_chi_tetrahedral_ccw\",\n",
    "    #     \"chiral_type_chi_other\",\n",
    "    #     \"chiral_type_chi_tetrahedral\",\n",
    "    #     \"chiral_type_chi_allene\",\n",
    "    #     \"chiral_type_chi_squareplanar\",\n",
    "    #     \"chiral_type_chi_trigonalbipyramidal\",\n",
    "    #     \"chiral_type_chi_octahedral\",\n",
    "    #     \"degree\",\n",
    "    #     \"radical_count\"\n",
    "    # ]\n",
    ")\n",
    "\n",
    "num_node_features = train_loader.dataset[0].num_node_features\n",
    "num_edge_features = train_loader.dataset[0].num_edge_features\n",
    "model = GNNSetRepRegressor(num_node_features, 512, 2, num_edge_features, 8, 16)\n",
    "# model = GNNRegressor(num_node_features, 512, 2, num_edge_features)\n",
    "# model = GNNSetRepRegressor(num_node_features, 512, 2, num_edge_features, 8, 32, gnn=GAT(num_node_features, 512, 4, jk=\"cat\", heads=8))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "explainer = RegressionExplainer(model, valid_loader)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    200,\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    [R2Score(), MeanSquaredError(squared=False)],\n",
    "    # scheduler=scheduler,\n",
    "    monitor_metric=1,\n",
    "    # monitor_lower_is_better=False\n",
    "    # explainer=explainer\n",
    ")\n",
    "\n",
    "trainer.train(train_loader, valid_loader)\n",
    "trainer.test(test_loader, average_n_epochs=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
