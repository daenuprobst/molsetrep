{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import Parameter, Linear, BatchNorm1d, ReLU, LeakyReLU, Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryAUROC\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError, MeanAbsoluteError\n",
    "from torchmetrics.classification import Accuracy, AUROC\n",
    "\n",
    "from molsetrep.utils.torch_trainer import TorchTrainer\n",
    "from molsetrep.utils.multiset_torch_trainer import MultisetTorchTrainer\n",
    "from molsetrep.utils.datasets import molnet_loader\n",
    "from molsetrep.utils.converters import molnet_to_pyg\n",
    "from molsetrep.utils.root_mean_squared_error import RootMeanSquaredError\n",
    "from molsetrep.utils.imbalanced_sampler import ImbalancedSampler\n",
    "# from molsetrep.models import SetRepClassifier, SetRepRegressor, GNNDeepSetClassifier, DeepSet, DualSetRepClassifier, DualSetRepRegressor\n",
    "from molsetrep.encoders import SECMQNFPEncoder, SECFPEncoder, ECFPEncoder, Mol2VecEncoder, Mol2SetEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning.pytorch as pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualSetClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_hidden_sets, n_hidden_sets_2, n_elements, n_elements_2, d, d_2):\n",
    "        super().__init__()\n",
    "        self.n_hidden_sets = n_hidden_sets\n",
    "        self.n_elements = n_elements\n",
    "\n",
    "        self.n_hidden_sets_2 = n_hidden_sets_2\n",
    "        self.n_elements_2 = n_elements_2\n",
    "\n",
    "        self.Wc = Parameter(torch.FloatTensor(d, n_hidden_sets * n_elements))\n",
    "        self.Wc_2 = Parameter(torch.FloatTensor(d_2, n_hidden_sets_2 * n_elements_2))\n",
    "        self.fc1 = Linear(n_hidden_sets, 32)\n",
    "        self.fc1_2 = Linear(n_hidden_sets_2, 32)\n",
    "        self.bn = BatchNorm1d(n_hidden_sets)\n",
    "        self.bn_2 = BatchNorm1d(n_hidden_sets_2)\n",
    "        self.dropout_1 = Dropout(0.8)\n",
    "        self.dropout_2 = Dropout(0.8)\n",
    "        self.fc2 = Linear(32 * 2, 32)\n",
    "        self.bn_3 = BatchNorm1d(32)\n",
    "        self.fc3 = Linear(32, 16)\n",
    "        self.fc4 = Linear(16, 1)\n",
    "\n",
    "        \n",
    "        # Init weights\n",
    "        self.Wc.data.normal_()\n",
    "        self.Wc_2.data.normal_()\n",
    "\n",
    "        # Metrics\n",
    "        self.train_r2score = R2Score()\n",
    "        self.train_rmse = MeanSquaredError(squared=False)\n",
    "        self.valid_r2score = R2Score()\n",
    "        self.valid_rmse = MeanSquaredError(squared=False)\n",
    "        self.test_r2score = R2Score()\n",
    "        self.test_rmse = MeanSquaredError(squared=False)\n",
    "\n",
    "    def forward(self, X, X2):\n",
    "        # First sets (e.g. atoms)\n",
    "        t = torch.matmul(X, self.Wc)\n",
    "        t = torch.relu(t)\n",
    "        t = t.view(t.size()[0], t.size()[1], self.n_elements, self.n_hidden_sets)\n",
    "        t, _ = torch.max(t, dim=2)\n",
    "        t = torch.sum(t, dim=1)\n",
    "        t = self.bn(t)\n",
    "        t = self.fc1(t)\n",
    "        # t = self.dropout_1(t)\n",
    "        t = torch.relu(t)\n",
    "\n",
    "        # Second sets (e.g. bonds)\n",
    "        t_2 = torch.matmul(X2, self.Wc_2)\n",
    "        t_2 = torch.relu(t_2)\n",
    "        t_2 = t_2.view(\n",
    "            t_2.size()[0], t_2.size()[1], self.n_elements_2, self.n_hidden_sets_2\n",
    "        )\n",
    "        t_2, _ = torch.max(t_2, dim=2)\n",
    "        t_2 = torch.sum(t_2, dim=1)\n",
    "        t_2 = self.bn_2(t_2)\n",
    "        t_2 = self.fc1_2(t_2)\n",
    "        # t_2 = self.dropout_1(t_2)\n",
    "        t_2 = torch.relu(t_2)\n",
    "\n",
    "        # Concat, mlp, and softmax\n",
    "        out = self.fc2(torch.cat((t, t_2), 1))\n",
    "        out = self.bn_3(out)\n",
    "        out = torch.relu(out)\n",
    "        # out = self.dropout_1(out)\n",
    "        out = self.fc3(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        \n",
    "        return out.squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, x2, y = batch\n",
    "        out = self(x, x2)\n",
    "        loss = F.mse_loss(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.train_r2score(out, y)\n",
    "        self.train_rmse(out, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, x2, y = val_batch\n",
    "        out = self.forward(x, x2)\n",
    "        loss = F.mse_loss(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.valid_r2score(out, y)\n",
    "        self.valid_rmse(out, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, val_batch, batch_idx):\n",
    "        x, x2, y = val_batch\n",
    "        out = self.forward(x, x2)\n",
    "        loss = F.mse_loss(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.test_r2score(out, y)\n",
    "        self.test_rmse(out, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_r2score\", self.test_r2score, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_rmse\", self.test_rmse, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train_r2score_epoch\", self.train_r2score)\n",
    "        self.log(\"train_rmse_epoch\", self.train_rmse)\n",
    "\n",
    "        print(\"Train RMSE\", self.train_rmse.compute())\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"valid_r2score_epoch\", self.valid_r2score)\n",
    "        self.log(\"valid_rmse_epoch\", self.valid_rmse)\n",
    "\n",
    "        print(\"Valid RMSE\", self.valid_rmse.compute())\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (231) must match the existing size (229) at non-singleton dimension 1.  Target sizes: [1, 231].  Tensor sizes: [229]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m train, valid, test \u001b[39m=\u001b[39m molnet_loader(\u001b[39m\"\u001b[39m\u001b[39mdelaney\u001b[39m\u001b[39m\"\u001b[39m, splitter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m enc \u001b[39m=\u001b[39m ECFPEncoder()\n\u001b[0;32m----> 5\u001b[0m train_dataset \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39;49mencode(train\u001b[39m.\u001b[39;49mids, [y[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m y \u001b[39min\u001b[39;49;00m train\u001b[39m.\u001b[39;49my], label_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat)\n\u001b[1;32m      6\u001b[0m valid_dataset \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mencode(valid\u001b[39m.\u001b[39mids, [y[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m valid\u001b[39m.\u001b[39my], label_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m      7\u001b[0m test_dataset \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mencode(test\u001b[39m.\u001b[39mids, [y[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m test\u001b[39m.\u001b[39my], label_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/code/molsetrep/src/molsetrep/encoders/ecfp_encoder.py:155\u001b[0m, in \u001b[0;36mECFPEncoder.encode\u001b[0;34m(self, smiles, labels, label_dtype)\u001b[0m\n\u001b[1;32m    152\u001b[0m     fps_b\u001b[39m.\u001b[39mappend(fp_bond)\n\u001b[1;32m    153\u001b[0m     fps_g\u001b[39m.\u001b[39mappend(fp_global)\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto_multi_tensor_dataset(fps_a, fps_b, labels, label_dtype)\n",
      "File \u001b[0;32m~/code/molsetrep/src/molsetrep/encoders/encoder.py:54\u001b[0m, in \u001b[0;36mEncoder.to_multi_tensor_dataset\u001b[0;34m(self, X, X2, y, y_dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m X2_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((n, max_cardinality, d))\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(X2):\n\u001b[0;32m---> 54\u001b[0m     X2_tensor[i, : \u001b[39mlen\u001b[39;49m(x), :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(np\u001b[39m.\u001b[39mnan_to_num(np\u001b[39m.\u001b[39marray(x)))\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m TensorDataset(X_tensor, X2_tensor, torch\u001b[39m.\u001b[39mtensor(y, dtype\u001b[39m=\u001b[39my_dtype))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (231) must match the existing size (229) at non-singleton dimension 1.  Target sizes: [1, 231].  Tensor sizes: [229]"
     ]
    }
   ],
   "source": [
    "train, valid, test = molnet_loader(\"delaney\", splitter=\"random\")\n",
    "\n",
    "enc = ECFPEncoder()\n",
    "\n",
    "train_dataset = enc.encode(train.ids, [y[0] for y in train.y], label_dtype=torch.float)\n",
    "valid_dataset = enc.encode(valid.ids, [y[0] for y in valid.y], label_dtype=torch.float)\n",
    "test_dataset = enc.encode(test.ids, [y[0] for y in test.y], label_dtype=torch.float)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, num_workers=8)#, sampler=ImbalancedSampler(train_dataset))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "\n",
    "d = len(train_dataset[0][0][0])\n",
    "d2 = len(train_dataset[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /home/daenu/code/molsetrep/notebooks/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0  | fc1            | Linear             | 544   \n",
      "1  | fc1_2          | Linear             | 544   \n",
      "2  | bn             | BatchNorm1d        | 32    \n",
      "3  | bn_2           | BatchNorm1d        | 32    \n",
      "4  | dropout_1      | Dropout            | 0     \n",
      "5  | dropout_2      | Dropout            | 0     \n",
      "6  | fc2            | Linear             | 2.1 K \n",
      "7  | bn_3           | BatchNorm1d        | 64    \n",
      "8  | fc3            | Linear             | 528   \n",
      "9  | fc4            | Linear             | 34    \n",
      "10 | train_accuracy | MulticlassAccuracy | 0     \n",
      "11 | train_auroc    | MulticlassAUROC    | 0     \n",
      "12 | valid_accuracy | MulticlassAccuracy | 0     \n",
      "13 | valid_auroc    | MulticlassAUROC    | 0     \n",
      "14 | test_accuracy  | MulticlassAccuracy | 0     \n",
      "15 | test_auroc     | MulticlassAUROC    | 0     \n",
      "-------------------------------------------------------\n",
      "51.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "51.5 K    Total params\n",
      "0.206     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176a85633b9e46da9e880be998003d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=100, log_every_n_steps=1, gradient_clip_val=0.5)\n",
    "model = DualSetClassifier(16, 16, 8, 8, d, d2, 2, class_weights=class_weights)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
