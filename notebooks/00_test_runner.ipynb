{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from molsetrep.utils.datasets import molnet_loader, get_class_weights\n",
    "from wandb import finish as wandb_finish\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import wandb\n",
    "import lightning.pytorch as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def molnet_test_runner(data_set_name, encoder, model, label_dtype, checkpoint_callback, max_epochs=50, batch_size=64):\n",
    "    train, valid, test, tasks = molnet_loader(data_set_name, splitter=\"random\")\n",
    "\n",
    "    for task in range(len(tasks)):\n",
    "        class_weights, class_counts = get_class_weights(train.y, task)\n",
    "        print(class_weights)\n",
    "        print(class_counts)\n",
    "\n",
    "        train_dataset = encoder.encode(train.ids, [y[task] for y in train.y], label_dtype=label_dtype)\n",
    "        valid_dataset = encoder.encode(valid.ids, [y[task] for y in valid.y], label_dtype=label_dtype)\n",
    "        test_dataset = encoder.encode(test.ids, [y[task] for y in test.y], label_dtype=label_dtype)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, drop_last=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, drop_last=True)\n",
    "\n",
    "        d = len(train_dataset[0][0][0])\n",
    "        d2 = len(train_dataset[0][1][0])\n",
    "        d3 = len(train_dataset[0][2][0])\n",
    "\n",
    "        for _ in range(4):\n",
    "            # Make sure no run is ongoing\n",
    "            wandb_finish()\n",
    "            \n",
    "            # Setup wandb logging\n",
    "            wandb_logger = wandb.WandbLogger(project=f\"MolRepSet-triple-{data_set_name}\")\n",
    "            wandb_logger.experiment.config[\"task\"] = tasks[task]\n",
    "\n",
    "            trainer = pl.Trainer(callbacks=[checkpoint_callback], max_epochs=max_epochs, log_every_n_steps=1, logger=wandb_logger)\n",
    "            wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "            trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "            trainer.test(ckpt_path=\"best\", dataloaders=test_loader)\n",
    "\n",
    "            wandb_logger.finalize(\"success\")\n",
    "            wandb_finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
