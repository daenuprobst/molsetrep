{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import Parameter, Linear, BatchNorm1d, ReLU, LeakyReLU, Linear, Dropout, CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryAUROC\n",
    "from torchmetrics.regression import R2Score, MeanSquaredError, MeanAbsoluteError\n",
    "from torchmetrics.classification import Accuracy, AUROC\n",
    "\n",
    "from molsetrep.utils.torch_trainer import TorchTrainer\n",
    "from molsetrep.utils.multiset_torch_trainer import MultisetTorchTrainer\n",
    "from molsetrep.utils.datasets import molnet_loader\n",
    "from molsetrep.utils.converters import molnet_to_pyg\n",
    "from molsetrep.utils.root_mean_squared_error import RootMeanSquaredError\n",
    "from molsetrep.utils.imbalanced_sampler import ImbalancedSampler\n",
    "# from molsetrep.models import SetRepClassifier, SetRepRegressor, GNNDeepSetClassifier, DeepSet, DualSetRepClassifier, DualSetRepRegressor\n",
    "from molsetrep.encoders import SECMQNFPEncoder, SECFPEncoder, DualSetEncoder, Mol2VecEncoder, Mol2SetEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import wandb\n",
    "from wandb import finish as wandb_finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualSetClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_hidden_sets, n_hidden_sets_2, n_elements, n_elements_2, d, d_2, n_classes, class_weights):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.n_hidden_sets = n_hidden_sets\n",
    "        self.n_elements = n_elements\n",
    "\n",
    "        self.n_hidden_sets_2 = n_hidden_sets_2\n",
    "        self.n_elements_2 = n_elements_2\n",
    "\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "        self.Wc = Parameter(torch.FloatTensor(d, n_hidden_sets * n_elements))\n",
    "        self.Wc_2 = Parameter(torch.FloatTensor(d_2, n_hidden_sets_2 * n_elements_2))\n",
    "        self.fc1 = Linear(n_hidden_sets, 32)\n",
    "        self.fc1_2 = Linear(n_hidden_sets_2, 32)\n",
    "        self.bn = BatchNorm1d(n_hidden_sets)\n",
    "        self.bn_2 = BatchNorm1d(n_hidden_sets_2)\n",
    "        self.dropout_1 = Dropout(0.8)\n",
    "        self.dropout_2 = Dropout(0.8)\n",
    "        self.fc2 = Linear(32 * 2, 32)\n",
    "        self.bn_3 = BatchNorm1d(32)\n",
    "        self.fc3 = Linear(32, 16)\n",
    "        self.fc4 = Linear(16, n_classes)\n",
    "\n",
    "        \n",
    "        # Init weights\n",
    "        # self.Wc.data.normal_()\n",
    "        # self.Wc_2.data.normal_()\n",
    "\n",
    "        self.Wc.data.uniform_(-1, 1)\n",
    "        self.Wc_2.data.uniform_(-1, 1)\n",
    "\n",
    "        # Metrics\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.train_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.test_auroc = AUROC(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "        self.criterion = CrossEntropyLoss(weight=torch.FloatTensor(self.class_weights).to(self.device))\n",
    "        self.criterion_eval = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, X, X2):\n",
    "        # First sets (e.g. atoms)\n",
    "        t = torch.matmul(X, self.Wc)\n",
    "\n",
    "        t = torch.relu(t)\n",
    "        t = t.view(t.size()[0], t.size()[1], self.n_elements, self.n_hidden_sets)\n",
    "        t, _ = torch.max(t, dim=2)\n",
    "        t = torch.sum(t, dim=1)\n",
    "        t = self.bn(t)\n",
    "\n",
    "        t = self.fc1(t)\n",
    "        # t = self.dropout_1(t)\n",
    "        t = torch.relu(t)\n",
    "\n",
    "        # Second sets (e.g. bonds)\n",
    "        t_2 = torch.matmul(X2, self.Wc_2)\n",
    "        t_2 = torch.relu(t_2)\n",
    "        t_2 = t_2.view(\n",
    "            t_2.size()[0], t_2.size()[1], self.n_elements_2, self.n_hidden_sets_2\n",
    "        )\n",
    "        t_2, _ = torch.max(t_2, dim=2)\n",
    "        t_2 = torch.sum(t_2, dim=1)\n",
    "        t_2 = self.bn_2(t_2)\n",
    "        t_2 = self.fc1_2(t_2)\n",
    "        # t_2 = self.dropout_1(t_2)\n",
    "        t_2 = torch.relu(t_2)\n",
    "\n",
    "        # Concat, mlp, and softmax\n",
    "        out = self.fc2(torch.cat((t, t_2), 1))\n",
    "\n",
    "        out = self.bn_3(out)\n",
    "        out = torch.relu(out)\n",
    "        # out = self.dropout_1(out)\n",
    "        out = self.fc3(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, x2, y = batch\n",
    "\n",
    "        out = self(x, x2)\n",
    "\n",
    "        loss = self.criterion(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.train_accuracy(out, y)\n",
    "        self.train_auroc(out, y)\n",
    "\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"train/acc\", self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        self.log(\"train/auroc\", self.train_auroc, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, x2, y = val_batch\n",
    "        out = self.forward(x, x2)\n",
    "\n",
    "        loss = self.criterion_eval(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.val_accuracy(out, y)\n",
    "        self.val_auroc(out, y)\n",
    "\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val/acc\", self.val_accuracy, on_step=False, on_epoch=True)\n",
    "        self.log(\"val/auroc\", self.val_auroc, on_step=False, on_epoch=True)\n",
    "\n",
    "    def test_step(self, val_batch, batch_idx):\n",
    "        x, x2, y = val_batch\n",
    "        out = self.forward(x, x2)\n",
    "        loss = self.criterion_eval(out, y)\n",
    "\n",
    "        # Metrics\n",
    "        self.test_accuracy(out, y)\n",
    "        self.test_auroc(out, y)\n",
    "\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc\", self.test_accuracy)\n",
    "        self.log(\"test/auroc\", self.test_auroc)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    n = len(y)\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    weights = [1 - c / n for c in counts]\n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = \"bbbp\"\n",
    "\n",
    "train, valid, test = molnet_loader(data_set_name, splitter=\"scaffold\")\n",
    "\n",
    "enc = DualSetEncoder()\n",
    "\n",
    "class_weights = get_class_weights(train.y.flatten())\n",
    "print(class_weights)\n",
    "\n",
    "train_dataset = enc.encode(train.ids, [y[0] for y in train.y], label_dtype=torch.long)\n",
    "valid_dataset = enc.encode(valid.ids, [y[0] for y in valid.y], label_dtype=torch.long)\n",
    "test_dataset = enc.encode(test.ids, [y[0] for y in test.y], label_dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, drop_last=True)\n",
    "\n",
    "d = len(train_dataset[0][0][0])\n",
    "d2 = len(train_dataset[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    # Setup wandb logging\n",
    "    wandb_logger = wandb.WandbLogger(project=f\"MolRepSet-{data_set_name}\")\n",
    "\n",
    "    # Define callback for which callpoint to load for testing\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val/auroc\", mode=\"max\")\n",
    "\n",
    "    trainer = pl.Trainer(callbacks=[checkpoint_callback], max_epochs=50, log_every_n_steps=1, logger=wandb_logger)\n",
    "\n",
    "    model = DualSetClassifier(128, 128, 128, 128, d, d2, 2, class_weights=class_weights)\n",
    "    wandb_logger.watch(model, log=\"all\")\n",
    "\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
    "    trainer.test(ckpt_path=\"best\", dataloaders=test_loader)\n",
    "\n",
    "    wandb_logger.finalize(\"success\")\n",
    "    wandb_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molsetrep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
